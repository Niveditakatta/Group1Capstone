{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classfiication_ChexnetWeights_adam2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o63KdJi1IjKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#import pydicom\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import os\n",
        "from matplotlib.patches import Rectangle\n",
        "import seaborn as sns\n",
        "import keras\n",
        "#from keras.applications.densenet import DenseNet121,DenseNet201, DenseNet169\n",
        "from keras.layers import Input\n",
        "from keras.models import Model, Sequential, model_from_json, load_model\n",
        "from keras.layers import Dense, InputLayer, AveragePooling2D, Flatten, Dropout, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "#from generator import DataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scVCofB3IZNU",
        "colab_type": "code",
        "outputId": "5885ab9f-b695-431e-b440-8ce941cce19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AP6acBR-PIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_dir = '/content/drive/My Drive/Capstone/PretrainedWeights/'\n",
        "\n",
        "chexnet_weights_file = os.path.join(weights_dir, 'brucechou1983_CheXNet_Keras_0.3.0_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8-RC9lTBI0J",
        "colab_type": "code",
        "outputId": "da7ddb54-b47b-4e40-b5ea-24903eea01ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/Capstone/PretrainedWeights/'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "brucechou1983_CheXNet_Keras_0.3.0_weights.h5  trained_model.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyviUiCU13sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create structure from trained and saved json file\n",
        "json_file=  open(weights_dir +'trained_model.json', 'r') #'model_train.h5')\n",
        "trained_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "\n",
        "chexnet_model = model_from_json(trained_model_json)\n",
        "\n",
        "#Load weights to newly created model from json\n",
        "chexnet_model.load_weights(chexnet_weights_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa1h5V_q2a-5",
        "colab_type": "code",
        "outputId": "64c329cb-e179-477a-e951-6353954e7c5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "chexnet_model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 14)           14350       avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 7,051,854\n",
            "Trainable params: 6,968,206\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-a05-Yt2j0a",
        "colab_type": "code",
        "outputId": "296e40e0-db2f-4f2b-bafd-f4a4a95efc7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#chexnet_model.layers.pop()\n",
        "#chexnet_model.layers.pop()\n",
        "chexnet_model.layers.pop()\n",
        "chexnet_model.layers.pop()\n",
        "chexnet_model.layers.pop()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.Activation at 0x7f35ae83dfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lPpJwz43lZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in chexnet_model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "temp_model = Sequential()\n",
        "temp_model.add(Dense(1024, activation='relu'))\n",
        "temp_model.add(Dropout(0.25))\n",
        "temp_model.add(Dense(512, activation='relu'))\n",
        "temp_model.add(Dropout(0.25))\n",
        "temp_model.add(Dense(256, activation='relu'))\n",
        "temp_model.add(Dropout(0.25))\n",
        "temp_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model = Model(inputs=chexnet_model.input, outputs=temp_model(chexnet_model.output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWHd0T01gFsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''for layer in chexnet_model.layers[:-1]:\n",
        "    layer.trainable=False\n",
        "\n",
        "temp_model = chexnet_model.layers[-2].output\n",
        "#temp_model=Flatten()(temp_model)\n",
        "temp_model = Dense(512, activation='relu')(temp_model)\n",
        "temp_model=Dropout(0.25)(temp_model)\n",
        "temp_model= Dense(256, activation='relu')(temp_model)\n",
        "predictions =Dense(1, activation='sigmoid')(temp_model)\n",
        "\n",
        "\n",
        "model = Model(inputs=chexnet_model.input, outputs= predictions)'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtda5Dw026Uv",
        "colab_type": "code",
        "outputId": "b0d36d06-be52-4b7c-d796-690bbe13d0b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 14)           14350       avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 1)            671745      predictions[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 7,723,599\n",
            "Trainable params: 686,095\n",
            "Non-trainable params: 7,037,504\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFUKyoZvQSlI",
        "colab_type": "code",
        "outputId": "fd0323d4-5129-4e26-b0ae-6029fe90ba09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.3,\n",
        "        zoom_range=0.3,\n",
        "        horizontal_flip=True)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/Capstone/train_png/',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=128,color_mode='rgb',\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/Capstone/validation_png/',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=128,color_mode='rgb',\n",
        "        class_mode='binary')\n",
        "\n",
        "'''test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/Capstone/test_png/',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=16,color_mode='rgb',\n",
        "        class_mode='binary')'''"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4838 images belonging to 2 classes.\n",
            "Found 441 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"test_generator = test_datagen.flow_from_directory(\\n        '/content/drive/My Drive/Capstone/test_png/',\\n        target_size=(224, 224),\\n        batch_size=16,color_mode='rgb',\\n        class_mode='binary')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXmi9VGngsQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#log loss or cross entropy \n",
        "adam = Adam(lr=0.001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcB6xzYLTb0b",
        "colab_type": "code",
        "outputId": "6d2714eb-ad40-4379-ab09-399d38222861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "#earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=0, mode='auto')\n",
        "reducelr =  ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.001, patience = 10, verbose = 0, mode = \"auto\", epsilon = 1e-08, cooldown = 0, min_lr = 0.0001)\n",
        "checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/Capstone/chexnet_weights_pnemonia_adam2.h5' , monitor='val_loss',verbose=1,save_best_only=True, save_weights_only=True,mode='val_acc' ,)\n",
        "batch_size=64\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=4800// batch_size,\n",
        "        epochs=100,\n",
        "        validation_data=validation_generator,callbacks=[checkpointer],\n",
        "        validation_steps=440 // batch_size)\n",
        "\n",
        "model.save(\"/content/drive/My Drive/Capstone/model_pnemonia_adam2.h5\")\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:407: RuntimeWarning: ModelCheckpoint mode val_acc is unknown, fallback to auto mode.\n",
            "  RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "75/75 [==============================] - 170s 2s/step - loss: 0.5440 - acc: 0.7252 - val_loss: 0.5473 - val_acc: 0.7145\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.54732, saving model to /content/drive/My Drive/Capstone/chexnet_weights_pnemonia_adam2.h5\n",
            "Epoch 2/100\n",
            "75/75 [==============================] - 154s 2s/step - loss: 0.4281 - acc: 0.8056 - val_loss: 0.6105 - val_acc: 0.6757\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.54732\n",
            "Epoch 3/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4180 - acc: 0.8070 - val_loss: 0.5697 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.54732\n",
            "Epoch 4/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.4136 - acc: 0.8081 - val_loss: 0.6338 - val_acc: 0.6629\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.54732\n",
            "Epoch 5/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4206 - acc: 0.8032 - val_loss: 0.5241 - val_acc: 0.7245\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.54732 to 0.52405, saving model to /content/drive/My Drive/Capstone/chexnet_weights_pnemonia_adam2.h5\n",
            "Epoch 6/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4080 - acc: 0.8140 - val_loss: 0.5907 - val_acc: 0.6981\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.52405\n",
            "Epoch 7/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.4085 - acc: 0.8094 - val_loss: 0.5797 - val_acc: 0.7059\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.52405\n",
            "Epoch 8/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4145 - acc: 0.8133 - val_loss: 0.5599 - val_acc: 0.6981\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.52405\n",
            "Epoch 9/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4083 - acc: 0.8099 - val_loss: 0.5623 - val_acc: 0.7016\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.52405\n",
            "Epoch 10/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4044 - acc: 0.8135 - val_loss: 0.5132 - val_acc: 0.7236\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.52405 to 0.51323, saving model to /content/drive/My Drive/Capstone/chexnet_weights_pnemonia_adam2.h5\n",
            "Epoch 11/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4137 - acc: 0.8072 - val_loss: 0.5119 - val_acc: 0.7288\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.51323 to 0.51187, saving model to /content/drive/My Drive/Capstone/chexnet_weights_pnemonia_adam2.h5\n",
            "Epoch 12/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4048 - acc: 0.8159 - val_loss: 0.5806 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.51187\n",
            "Epoch 13/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4013 - acc: 0.8175 - val_loss: 0.5694 - val_acc: 0.7116\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.51187\n",
            "Epoch 14/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4040 - acc: 0.8118 - val_loss: 0.5415 - val_acc: 0.7061\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.51187\n",
            "Epoch 15/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4007 - acc: 0.8153 - val_loss: 0.6036 - val_acc: 0.6872\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.51187\n",
            "Epoch 16/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.4054 - acc: 0.8129 - val_loss: 0.5701 - val_acc: 0.7141\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.51187\n",
            "Epoch 17/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4061 - acc: 0.8108 - val_loss: 0.5769 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.51187\n",
            "Epoch 18/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4037 - acc: 0.8152 - val_loss: 0.5286 - val_acc: 0.7300\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.51187\n",
            "Epoch 19/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4053 - acc: 0.8073 - val_loss: 0.5368 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.51187\n",
            "Epoch 20/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.4109 - acc: 0.8087 - val_loss: 0.5547 - val_acc: 0.7141\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.51187\n",
            "Epoch 21/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4048 - acc: 0.8139 - val_loss: 0.5912 - val_acc: 0.7016\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.51187\n",
            "Epoch 22/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4097 - acc: 0.8102 - val_loss: 0.6316 - val_acc: 0.6789\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.51187\n",
            "Epoch 23/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4080 - acc: 0.8130 - val_loss: 0.5144 - val_acc: 0.7389\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.51187\n",
            "Epoch 24/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4042 - acc: 0.8153 - val_loss: 0.5178 - val_acc: 0.7316\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.51187\n",
            "Epoch 25/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4046 - acc: 0.8134 - val_loss: 0.5853 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.51187\n",
            "Epoch 26/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4034 - acc: 0.8167 - val_loss: 0.5931 - val_acc: 0.6757\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.51187\n",
            "Epoch 27/100\n",
            "75/75 [==============================] - 160s 2s/step - loss: 0.4044 - acc: 0.8162 - val_loss: 0.6202 - val_acc: 0.6944\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.51187\n",
            "Epoch 28/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4025 - acc: 0.8137 - val_loss: 0.5288 - val_acc: 0.7300\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.51187\n",
            "Epoch 29/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.3996 - acc: 0.8176 - val_loss: 0.5681 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.51187\n",
            "Epoch 30/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4009 - acc: 0.8196 - val_loss: 0.5552 - val_acc: 0.6997\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.51187\n",
            "Epoch 31/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4013 - acc: 0.8163 - val_loss: 0.6079 - val_acc: 0.6973\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.51187\n",
            "Epoch 32/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.3990 - acc: 0.8131 - val_loss: 0.5827 - val_acc: 0.6981\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.51187\n",
            "Epoch 33/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4019 - acc: 0.8148 - val_loss: 0.5824 - val_acc: 0.7016\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.51187\n",
            "Epoch 34/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.3957 - acc: 0.8184 - val_loss: 0.5638 - val_acc: 0.6933\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.51187\n",
            "Epoch 35/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4065 - acc: 0.8135 - val_loss: 0.5465 - val_acc: 0.7288\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.51187\n",
            "Epoch 36/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.3992 - acc: 0.8146 - val_loss: 0.6739 - val_acc: 0.6390\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.51187\n",
            "Epoch 37/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4031 - acc: 0.8119 - val_loss: 0.5777 - val_acc: 0.7088\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.51187\n",
            "Epoch 38/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.4000 - acc: 0.8176 - val_loss: 0.5844 - val_acc: 0.6917\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.51187\n",
            "Epoch 39/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3955 - acc: 0.8195 - val_loss: 0.5949 - val_acc: 0.6973\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.51187\n",
            "Epoch 40/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.3924 - acc: 0.8215 - val_loss: 0.5163 - val_acc: 0.7236\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.51187\n",
            "Epoch 41/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.4011 - acc: 0.8125 - val_loss: 0.5586 - val_acc: 0.7088\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.51187\n",
            "Epoch 42/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.4035 - acc: 0.8154 - val_loss: 0.5086 - val_acc: 0.7572\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.51187 to 0.50861, saving model to /content/drive/My Drive/Capstone/chexnet_weights_pnemonia_adam2.h5\n",
            "Epoch 43/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3930 - acc: 0.8205 - val_loss: 0.5914 - val_acc: 0.6915\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.50861\n",
            "Epoch 44/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3996 - acc: 0.8180 - val_loss: 0.5613 - val_acc: 0.6997\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.50861\n",
            "Epoch 45/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3974 - acc: 0.8163 - val_loss: 0.5907 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.50861\n",
            "Epoch 46/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3951 - acc: 0.8185 - val_loss: 0.6773 - val_acc: 0.6518\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.50861\n",
            "Epoch 47/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.4051 - acc: 0.8176 - val_loss: 0.5501 - val_acc: 0.6958\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.50861\n",
            "Epoch 48/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3982 - acc: 0.8156 - val_loss: 0.6318 - val_acc: 0.6757\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.50861\n",
            "Epoch 49/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3939 - acc: 0.8212 - val_loss: 0.5597 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.50861\n",
            "Epoch 50/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.3976 - acc: 0.8198 - val_loss: 0.5383 - val_acc: 0.7077\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.50861\n",
            "Epoch 51/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.3987 - acc: 0.8138 - val_loss: 0.5243 - val_acc: 0.7202\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.50861\n",
            "Epoch 52/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3928 - acc: 0.8195 - val_loss: 0.6325 - val_acc: 0.6789\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.50861\n",
            "Epoch 53/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3958 - acc: 0.8197 - val_loss: 0.4910 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.50861 to 0.49098, saving model to /content/drive/My Drive/Capstone/chexnet_weights_pnemonia_adam2.h5\n",
            "Epoch 54/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4002 - acc: 0.8152 - val_loss: 0.5930 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.49098\n",
            "Epoch 55/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3988 - acc: 0.8162 - val_loss: 0.5350 - val_acc: 0.7088\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.49098\n",
            "Epoch 56/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3914 - acc: 0.8203 - val_loss: 0.6155 - val_acc: 0.6789\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.49098\n",
            "Epoch 57/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3939 - acc: 0.8200 - val_loss: 0.5089 - val_acc: 0.7489\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.49098\n",
            "Epoch 58/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.4007 - acc: 0.8162 - val_loss: 0.5675 - val_acc: 0.7077\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.49098\n",
            "Epoch 59/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3893 - acc: 0.8225 - val_loss: 0.5454 - val_acc: 0.7116\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.49098\n",
            "Epoch 60/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3977 - acc: 0.8190 - val_loss: 0.6274 - val_acc: 0.6629\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.49098\n",
            "Epoch 61/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3974 - acc: 0.8162 - val_loss: 0.7514 - val_acc: 0.5753\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.49098\n",
            "Epoch 62/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3947 - acc: 0.8195 - val_loss: 0.5135 - val_acc: 0.7284\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.49098\n",
            "Epoch 63/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3913 - acc: 0.8224 - val_loss: 0.5994 - val_acc: 0.7102\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.49098\n",
            "Epoch 64/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3967 - acc: 0.8156 - val_loss: 0.5155 - val_acc: 0.7300\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.49098\n",
            "Epoch 65/100\n",
            "75/75 [==============================] - 160s 2s/step - loss: 0.3988 - acc: 0.8141 - val_loss: 0.5034 - val_acc: 0.7360\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.49098\n",
            "Epoch 66/100\n",
            "75/75 [==============================] - 160s 2s/step - loss: 0.3992 - acc: 0.8171 - val_loss: 0.5204 - val_acc: 0.7268\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.49098\n",
            "Epoch 67/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.3879 - acc: 0.8225 - val_loss: 0.5617 - val_acc: 0.7102\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.49098\n",
            "Epoch 68/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.3954 - acc: 0.8186 - val_loss: 0.5896 - val_acc: 0.7029\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.49098\n",
            "Epoch 69/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.3902 - acc: 0.8198 - val_loss: 0.6313 - val_acc: 0.7102\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.49098\n",
            "Epoch 70/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.3834 - acc: 0.8222 - val_loss: 0.5540 - val_acc: 0.7045\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.49098\n",
            "Epoch 71/100\n",
            "75/75 [==============================] - 160s 2s/step - loss: 0.3981 - acc: 0.8189 - val_loss: 0.5524 - val_acc: 0.7116\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.49098\n",
            "Epoch 72/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.3935 - acc: 0.8199 - val_loss: 0.5864 - val_acc: 0.6965\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.49098\n",
            "Epoch 73/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.3951 - acc: 0.8214 - val_loss: 0.6199 - val_acc: 0.6686\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.49098\n",
            "Epoch 74/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.3873 - acc: 0.8219 - val_loss: 0.5780 - val_acc: 0.7109\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.49098\n",
            "Epoch 75/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.3902 - acc: 0.8200 - val_loss: 0.6353 - val_acc: 0.6729\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.49098\n",
            "Epoch 76/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3900 - acc: 0.8220 - val_loss: 0.5767 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.49098\n",
            "Epoch 77/100\n",
            "75/75 [==============================] - 160s 2s/step - loss: 0.3867 - acc: 0.8185 - val_loss: 0.5399 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.49098\n",
            "Epoch 78/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3907 - acc: 0.8196 - val_loss: 0.5484 - val_acc: 0.7125\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.49098\n",
            "Epoch 79/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3960 - acc: 0.8158 - val_loss: 0.5663 - val_acc: 0.7102\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.49098\n",
            "Epoch 80/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3948 - acc: 0.8222 - val_loss: 0.5345 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.49098\n",
            "Epoch 81/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3917 - acc: 0.8175 - val_loss: 0.5726 - val_acc: 0.7016\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.49098\n",
            "Epoch 82/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.3869 - acc: 0.8192 - val_loss: 0.5279 - val_acc: 0.7173\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.49098\n",
            "Epoch 83/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.6960 - val_acc: 0.6743\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.49098\n",
            "Epoch 84/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.3996 - acc: 0.8168 - val_loss: 0.5232 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.49098\n",
            "Epoch 85/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.3915 - acc: 0.8195 - val_loss: 0.5719 - val_acc: 0.7001\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.49098\n",
            "Epoch 86/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.3888 - acc: 0.8222 - val_loss: 0.5778 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.49098\n",
            "Epoch 87/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.3905 - acc: 0.8193 - val_loss: 0.6054 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.49098\n",
            "Epoch 88/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3900 - acc: 0.8195 - val_loss: 0.5237 - val_acc: 0.7236\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.49098\n",
            "Epoch 89/100\n",
            "75/75 [==============================] - 160s 2s/step - loss: 0.3922 - acc: 0.8223 - val_loss: 0.5362 - val_acc: 0.7231\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.49098\n",
            "Epoch 90/100\n",
            "75/75 [==============================] - 159s 2s/step - loss: 0.3909 - acc: 0.8227 - val_loss: 0.5760 - val_acc: 0.6981\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.49098\n",
            "Epoch 91/100\n",
            "75/75 [==============================] - 158s 2s/step - loss: 0.3926 - acc: 0.8158 - val_loss: 0.5777 - val_acc: 0.6944\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.49098\n",
            "Epoch 92/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.3930 - acc: 0.8158 - val_loss: 0.5373 - val_acc: 0.7316\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.49098\n",
            "Epoch 93/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3954 - acc: 0.8167 - val_loss: 0.6089 - val_acc: 0.6829\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.49098\n",
            "Epoch 94/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3920 - acc: 0.8202 - val_loss: 0.6168 - val_acc: 0.6789\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.49098\n",
            "Epoch 95/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3904 - acc: 0.8200 - val_loss: 0.5575 - val_acc: 0.7102\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.49098\n",
            "Epoch 96/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3893 - acc: 0.8209 - val_loss: 0.6124 - val_acc: 0.6581\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.49098\n",
            "Epoch 97/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3884 - acc: 0.8220 - val_loss: 0.5745 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.49098\n",
            "Epoch 98/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3974 - acc: 0.8178 - val_loss: 0.5718 - val_acc: 0.7045\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.49098\n",
            "Epoch 99/100\n",
            "75/75 [==============================] - 157s 2s/step - loss: 0.3855 - acc: 0.8217 - val_loss: 0.6170 - val_acc: 0.6944\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.49098\n",
            "Epoch 100/100\n",
            "75/75 [==============================] - 156s 2s/step - loss: 0.3951 - acc: 0.8186 - val_loss: 0.6095 - val_acc: 0.6821\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.49098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOFACfC7aZnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for layer in model.layers:\n",
        " #   layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ORGb2XalSP",
        "colab_type": "code",
        "outputId": "7a231f77-fd38-4c64-db5e-b5670c85c24e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Check the trainable status of the individual layers\n",
        "for layer in model.layers:\n",
        "  print(layer, layer.trainable)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f284c323518> False\n",
            "<keras.layers.convolutional.ZeroPadding2D object at 0x7f284c323588> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284c323748> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284c3237b8> False\n",
            "<keras.layers.core.Activation object at 0x7f284c3239e8> False\n",
            "<keras.layers.convolutional.ZeroPadding2D object at 0x7f284c323be0> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f284c323c18> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284c323c50> False\n",
            "<keras.layers.core.Activation object at 0x7f284c323cf8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284c323e10> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284c323e48> False\n",
            "<keras.layers.core.Activation object at 0x7f284babc128> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284babc160> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284babc2e8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284babc320> False\n",
            "<keras.layers.core.Activation object at 0x7f284babc438> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284babc470> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284babc5f8> False\n",
            "<keras.layers.core.Activation object at 0x7f284babc710> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284babc748> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284babc8d0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284babc908> False\n",
            "<keras.layers.core.Activation object at 0x7f284babca20> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284babca58> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284babcbe0> False\n",
            "<keras.layers.core.Activation object at 0x7f284babccf8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284babcd30> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284babceb8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284babcef0> False\n",
            "<keras.layers.core.Activation object at 0x7f284c323fd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bac3080> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bac3208> False\n",
            "<keras.layers.core.Activation object at 0x7f284bac3320> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bac3358> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284bac34e0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bac3518> False\n",
            "<keras.layers.core.Activation object at 0x7f284bac3630> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bac3668> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bac37f0> False\n",
            "<keras.layers.core.Activation object at 0x7f284bac3908> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bac3940> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284bac3ac8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bac3b00> False\n",
            "<keras.layers.core.Activation object at 0x7f284bac3c18> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bac3c50> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bac3dd8> False\n",
            "<keras.layers.core.Activation object at 0x7f284bac3ef0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bac3f28> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284bacc0f0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bacc128> False\n",
            "<keras.layers.core.Activation object at 0x7f284bacc240> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bacc278> False\n",
            "<keras.layers.pooling.AveragePooling2D object at 0x7f284bacc400> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bacc4a8> False\n",
            "<keras.layers.core.Activation object at 0x7f284bacc5c0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bacc5f8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bacc780> False\n",
            "<keras.layers.core.Activation object at 0x7f284bacc898> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bacc8d0> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284bacca58> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bacca90> False\n",
            "<keras.layers.core.Activation object at 0x7f284baccba8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baccbe0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baccd68> False\n",
            "<keras.layers.core.Activation object at 0x7f284bacce80> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bacceb8> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284bad4080> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bad40b8> False\n",
            "<keras.layers.core.Activation object at 0x7f284bad41d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bad4208> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bad4390> False\n",
            "<keras.layers.core.Activation object at 0x7f284bad44a8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bad44e0> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284bad4668> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bad46a0> False\n",
            "<keras.layers.core.Activation object at 0x7f284bad47b8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bad47f0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bad4978> False\n",
            "<keras.layers.core.Activation object at 0x7f284bad4a90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bad4ac8> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284bad4c50> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bad4c88> False\n",
            "<keras.layers.core.Activation object at 0x7f284bad4da0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bad4dd8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bad4f60> False\n",
            "<keras.layers.core.Activation object at 0x7f284babcfd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284badb0f0> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284badb278> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284badb2b0> False\n",
            "<keras.layers.core.Activation object at 0x7f284badb3c8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284badb400> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284badb588> False\n",
            "<keras.layers.core.Activation object at 0x7f284badb6a0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284badb6d8> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284badb860> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284badb898> False\n",
            "<keras.layers.core.Activation object at 0x7f284badb9b0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284badb9e8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284badbb70> False\n",
            "<keras.layers.core.Activation object at 0x7f284badbc88> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284badbcc0> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284badbe48> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284badbe80> False\n",
            "<keras.layers.core.Activation object at 0x7f284badbf98> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bad4fd0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bae2198> False\n",
            "<keras.layers.core.Activation object at 0x7f284bae22b0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bae22e8> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284bae2470> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bae24a8> False\n",
            "<keras.layers.core.Activation object at 0x7f284bae25c0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bae25f8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bae2780> False\n",
            "<keras.layers.core.Activation object at 0x7f284bae2898> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bae28d0> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284bae2a58> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bae2a90> False\n",
            "<keras.layers.core.Activation object at 0x7f284bae2ba8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bae2be0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bae2d68> False\n",
            "<keras.layers.core.Activation object at 0x7f284bae2e80> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bae2eb8> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284baec080> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baec0b8> False\n",
            "<keras.layers.core.Activation object at 0x7f284baec1d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baec208> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baec390> False\n",
            "<keras.layers.core.Activation object at 0x7f284baec4a8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baec4e0> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284baec668> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baec6a0> False\n",
            "<keras.layers.core.Activation object at 0x7f284baec7b8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baec7f0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baec978> False\n",
            "<keras.layers.core.Activation object at 0x7f284baeca90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baecac8> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284baecc50> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baecc88> False\n",
            "<keras.layers.core.Activation object at 0x7f284baecda0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baecdd8> False\n",
            "<keras.layers.pooling.AveragePooling2D object at 0x7f284baecf60> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baf2048> False\n",
            "<keras.layers.core.Activation object at 0x7f284baf2160> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baf2198> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baf2320> False\n",
            "<keras.layers.core.Activation object at 0x7f284baf2438> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baf2470> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284baf25f8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baf2630> False\n",
            "<keras.layers.core.Activation object at 0x7f284baf2748> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baf2780> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baf2908> False\n",
            "<keras.layers.core.Activation object at 0x7f284baf2a20> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baf2a58> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284baf2be0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baf2c18> False\n",
            "<keras.layers.core.Activation object at 0x7f284baf2d30> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baf2d68> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baf2ef0> False\n",
            "<keras.layers.core.Activation object at 0x7f284badbfd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba79080> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba79208> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba79240> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba79358> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba79390> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba79518> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba79630> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba79668> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba797f0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba79828> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba79940> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba79978> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba79b00> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba79c18> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba79c50> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba79dd8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba79e10> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba79f28> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba79f60> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba82128> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba82240> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba82278> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba82400> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba82438> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba82550> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba82588> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba82710> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba82828> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba82860> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba829e8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba82a20> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba82b38> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba82b70> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba82cf8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba82e10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba82e48> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284baf2fd0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba89048> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba89160> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba89198> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba89320> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba89438> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba89470> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba895f8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba89630> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba89748> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba89780> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba89908> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba89a20> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba89a58> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba89be0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba89c18> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba89d30> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba89d68> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba89ef0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba82fd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba91080> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba91208> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba91240> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba91358> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba91390> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba91518> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba91630> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba91668> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba917f0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba91828> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba91940> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba91978> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba91b00> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba91c18> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba91c50> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba91dd8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba91e10> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba91f28> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba91f60> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba99128> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba99240> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba99278> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba99400> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba99438> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba99550> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba99588> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba99710> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba99828> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba99860> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba999e8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba99a20> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba99b38> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba99b70> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba99cf8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba99e10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba99e48> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba89fd0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baa2048> False\n",
            "<keras.layers.core.Activation object at 0x7f284baa2160> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baa2198> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baa2320> False\n",
            "<keras.layers.core.Activation object at 0x7f284baa2438> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baa2470> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284baa25f8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baa2630> False\n",
            "<keras.layers.core.Activation object at 0x7f284baa2748> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baa2780> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baa2908> False\n",
            "<keras.layers.core.Activation object at 0x7f284baa2a20> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baa2a58> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284baa2be0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baa2c18> False\n",
            "<keras.layers.core.Activation object at 0x7f284baa2d30> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baa2d68> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baa2ef0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba99fd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baa9080> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284baa9208> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baa9240> False\n",
            "<keras.layers.core.Activation object at 0x7f284baa9358> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baa9390> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baa9518> False\n",
            "<keras.layers.core.Activation object at 0x7f284baa9630> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baa9668> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284baa97f0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baa9828> False\n",
            "<keras.layers.core.Activation object at 0x7f284baa9940> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baa9978> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baa9b00> False\n",
            "<keras.layers.core.Activation object at 0x7f284baa9c18> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baa9c50> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284baa9dd8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284baa9e10> False\n",
            "<keras.layers.core.Activation object at 0x7f284baa9f28> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284baa9f60> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bab1128> False\n",
            "<keras.layers.core.Activation object at 0x7f284bab1240> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bab1278> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284bab1400> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bab1438> False\n",
            "<keras.layers.core.Activation object at 0x7f284bab1550> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bab1588> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bab1710> False\n",
            "<keras.layers.core.Activation object at 0x7f284bab1828> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bab1860> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284bab19e8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bab1a20> False\n",
            "<keras.layers.core.Activation object at 0x7f284bab1b38> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bab1b70> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284bab1cf8> False\n",
            "<keras.layers.core.Activation object at 0x7f284bab1e10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284bab1e48> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284baa2fd0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba39048> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba39160> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba39198> False\n",
            "<keras.layers.pooling.AveragePooling2D object at 0x7f284ba39320> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba393c8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba394e0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba39518> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba396a0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba397b8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba397f0> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba39978> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba399b0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba39ac8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba39b00> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba39c88> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba39da0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba39dd8> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba39f60> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba39f98> False\n",
            "<keras.layers.core.Activation object at 0x7f284bab1fd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba40128> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba402b0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba403c8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba40400> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba40588> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba405c0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba406d8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba40710> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba40898> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba409b0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba409e8> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba40b70> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba40ba8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba40cc0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba40cf8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba40e80> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba40f98> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba39fd0> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba48198> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba481d0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba482e8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba48320> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba484a8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba485c0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba485f8> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba48780> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba487b8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba488d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba48908> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba48a90> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba48ba8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba48be0> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba48d68> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba48da0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba48eb8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba48ef0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba500b8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba501d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba50208> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba50390> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba503c8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba504e0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba50518> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba506a0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba507b8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba507f0> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba50978> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba509b0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba50ac8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba50b00> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba50c88> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba50da0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba50dd8> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba50f60> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba50f98> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba40fd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba5b128> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba5b2b0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba5b3c8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba5b400> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba5b588> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba5b5c0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba5b6d8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba5b710> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba5b898> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba5b9b0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba5b9e8> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba5bb70> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba5bba8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba5bcc0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba5bcf8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba5be80> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba5bf98> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba50fd0> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba62198> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba621d0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba622e8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba62320> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba624a8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba625c0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba625f8> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba62780> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba627b8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba628d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba62908> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba62a90> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba62ba8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba62be0> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba62d68> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba62da0> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba62eb8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba62ef0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba690b8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba691d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f284ba69208> False\n",
            "<keras.layers.merge.Concatenate object at 0x7f284ba69390> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f284ba693c8> False\n",
            "<keras.layers.core.Activation object at 0x7f284ba694e0> True\n",
            "<keras.layers.pooling.GlobalAveragePooling2D object at 0x7f284ba69518> True\n",
            "<keras.layers.core.Dense object at 0x7f284ba69588> True\n",
            "<keras.engine.sequential.Sequential object at 0x7f27e2077588> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtpNhtSe21LU",
        "colab_type": "code",
        "outputId": "7e57b20d-6ba3-4dfd-ac74-120e60c4f765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6-8Jgo1zm4d",
        "colab_type": "code",
        "outputId": "7413d29f-0bf3-4d14-c308-8a1e5e34c6a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import os\n",
        "import cv2 \n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "patientID=[]\n",
        "filename=[]\n",
        "TestDir= '/content/drive/My Drive/Capstone/validation_png/'\n",
        "\n",
        "# loop over the input images\n",
        "dirs = os.listdir(TestDir) \n",
        "for dir in dirs:\n",
        "    absDirPath = os.path.join(os.path.sep,TestDir, dir)\n",
        "    images = os.listdir(absDirPath)\n",
        "    for imageFileName in images:\n",
        "        \n",
        "        # load the image, pre-process it, and store it in the data list\n",
        "        imageFullPath = os.path.join(TestDir, dir, imageFileName)\n",
        "        #print(imageFullPath)\n",
        "        img = load_img(imageFullPath)\n",
        "        arr = img_to_array(img)  #Numpy array with shape (233,233,3)\n",
        "        arr = cv2.resize(arr, (224,224)) #Numpy array with shape (HEIGHT, WIDTH,3)\n",
        "        #print(arr.shape)\n",
        "        data.append(arr)\n",
        "        patientID.append(imageFileName.split('/')[-1].split('.')[0])\n",
        "        #print(patientID)\n",
        "        filename.append(imageFullPath)\n",
        "        \n",
        "        #label = classes_to_int(dir)\n",
        "        if(dir== 'validation_pneumonia'):\n",
        "          label=1\n",
        "        else:\n",
        "          label=0\n",
        "        #print(label)\n",
        "        labels.append(label)\n",
        "    print(len(images))\n",
        "    \n",
        "print('Number of images :-',len(data))\n",
        "print('Number of Labels',len(labels))\n",
        "print('Number of patientID :-',len(patientID))\n",
        "print(len(filename))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "191\n",
            "250\n",
            "Number of images :- 441\n",
            "Number of Labels 441\n",
            "Number of patientID :- 441\n",
            "441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnMHsKkjzm8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Valid_df = pd.DataFrame({ \n",
        "                        'patientId':patientID,\n",
        "                       'images':data,\n",
        "                        'Labels': labels,\n",
        "                         'Filenames':filename\n",
        "                         })\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtvCbd4xzmom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model= load_model(\"/content/drive/My Drive/Capstone/model_pnemonia_adam2.h5\")\n",
        "y_preds=[]\n",
        "for img in Valid_df['images']:\n",
        "  img=img.reshape(-1,224,224,3)\n",
        "  pred_1=model.predict(img)\n",
        "  y_preds.append(pred_1)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xty8qxc9HuJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Valid_df['preds']=y_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIo2wjpgHzz0",
        "colab_type": "code",
        "outputId": "6cda9844-5c5b-4e91-bced-c430c6e9b952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "Valid_df['Labels'].value_counts()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    250\n",
              "1    191\n",
              "Name: Labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpFgO4LmFlMY",
        "colab_type": "code",
        "outputId": "c01e1d6b-e88d-43eb-f65c-91d8f2b02ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Valid_df[['Labels', 'preds']]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>preds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>0</td>\n",
              "      <td>[[0.028730966]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>441 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Labels            preds\n",
              "0         1  [[0.028730966]]\n",
              "1         1  [[0.028730966]]\n",
              "2         1  [[0.028730966]]\n",
              "3         1  [[0.028730966]]\n",
              "4         1  [[0.028730966]]\n",
              "5         1  [[0.028730966]]\n",
              "6         1  [[0.028730966]]\n",
              "7         1  [[0.028730966]]\n",
              "8         1  [[0.028730966]]\n",
              "9         1  [[0.028730966]]\n",
              "10        1  [[0.028730966]]\n",
              "11        1  [[0.028730966]]\n",
              "12        1  [[0.028730966]]\n",
              "13        1  [[0.028730966]]\n",
              "14        1  [[0.028730966]]\n",
              "15        1  [[0.028730966]]\n",
              "16        1  [[0.028730966]]\n",
              "17        1  [[0.028730966]]\n",
              "18        1  [[0.028730966]]\n",
              "19        1  [[0.028730966]]\n",
              "20        1  [[0.028730966]]\n",
              "21        1  [[0.028730966]]\n",
              "22        1  [[0.028730966]]\n",
              "23        1  [[0.028730966]]\n",
              "24        1  [[0.028730966]]\n",
              "25        1  [[0.028730966]]\n",
              "26        1  [[0.028730966]]\n",
              "27        1  [[0.028730966]]\n",
              "28        1  [[0.028730966]]\n",
              "29        1  [[0.028730966]]\n",
              "..      ...              ...\n",
              "411       0  [[0.028730966]]\n",
              "412       0  [[0.028730966]]\n",
              "413       0  [[0.028730966]]\n",
              "414       0  [[0.028730966]]\n",
              "415       0  [[0.028730966]]\n",
              "416       0  [[0.028730966]]\n",
              "417       0  [[0.028730966]]\n",
              "418       0  [[0.028730966]]\n",
              "419       0  [[0.028730966]]\n",
              "420       0  [[0.028730966]]\n",
              "421       0  [[0.028730966]]\n",
              "422       0  [[0.028730966]]\n",
              "423       0  [[0.028730966]]\n",
              "424       0  [[0.028730966]]\n",
              "425       0  [[0.028730966]]\n",
              "426       0  [[0.028730966]]\n",
              "427       0  [[0.028730966]]\n",
              "428       0  [[0.028730966]]\n",
              "429       0  [[0.028730966]]\n",
              "430       0  [[0.028730966]]\n",
              "431       0  [[0.028730966]]\n",
              "432       0  [[0.028730966]]\n",
              "433       0  [[0.028730966]]\n",
              "434       0  [[0.028730966]]\n",
              "435       0  [[0.028730966]]\n",
              "436       0  [[0.028730966]]\n",
              "437       0  [[0.028730966]]\n",
              "438       0  [[0.028730966]]\n",
              "439       0  [[0.028730966]]\n",
              "440       0  [[0.028730966]]\n",
              "\n",
              "[441 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ92Qqmr_I_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_preds_1=y_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ios1E40_8GAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds=[]\n",
        "for i, predicted in enumerate(y_preds_1):\n",
        "  if (predicted[0][0])>=0.4:\n",
        "    value=1\n",
        "    preds.append(value)\n",
        "      \n",
        "    \n",
        "  else :\n",
        "    value=0\n",
        "    preds.append(value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnutrg-YC-54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_val=Valid_df['Labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsmIx7pG8Pud",
        "colab_type": "code",
        "outputId": "40ad7970-4269-49ed-bc55-db92775c3767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "print(\"\\nConfusion_Marix is :\\n\",confusion_matrix(y_val, preds))\n",
        "print(\"\\nClassification_Report is :\\n\",classification_report(y_val,preds))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion_Marix is :\n",
            " [[250   0]\n",
            " [191   0]]\n",
            "\n",
            "Classification_Report is :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      1.00      0.72       250\n",
            "           1       0.00      0.00      0.00       191\n",
            "\n",
            "    accuracy                           0.57       441\n",
            "   macro avg       0.28      0.50      0.36       441\n",
            "weighted avg       0.32      0.57      0.41       441\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH6nOyLH8PrT",
        "colab_type": "code",
        "outputId": "ecfecf18-7ded-4bdb-a398-e4c3c02d25e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_val, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4bTOl8i8PoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tch1Y9lF8Pk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT4Hfs108Phk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2sBkx3qY9RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrAjWMMPY9bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj58xsZKY9NW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7RaQAfRY9Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0l80VVFY9GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}