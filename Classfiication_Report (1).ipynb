{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classfiication_Report.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFq6w89vFAPg",
        "colab_type": "code",
        "outputId": "d28bfcbb-69d4-4120-ccd5-888c96b6c452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "pip install pydicom"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/88/d3c419ab2e753e7651510882a53219373e78fb55294cb247dffd3934ea55/pydicom-1.2.2-py2.py3-none-any.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 4.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o63KdJi1IjKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import os\n",
        "from matplotlib.patches import Rectangle\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scVCofB3IZNU",
        "colab_type": "code",
        "outputId": "bb05ebbf-e633-4c35-80ad-1d55ce3dbd02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iqVjhmFJKzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "#os.chdir('/content/drive/My Drive/RSNA')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty-jLEU_PSnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "#from generator import DataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFUKyoZvQSlI",
        "colab_type": "code",
        "outputId": "294bae45-dcb1-4691-f199-b14f896b6005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/train_png/',\n",
        "        target_size=(256, 256),\n",
        "        batch_size=16,color_mode='rgb',\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/validation_png/',\n",
        "        target_size=(256, 256),\n",
        "        batch_size=16,color_mode='rgb',\n",
        "        class_mode='binary')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4838 images belonging to 2 classes.\n",
            "Found 441 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1ZThef6Pnio",
        "colab_type": "code",
        "outputId": "8d759fab-0c05-4cc7-90e7-f6f12af41909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "input_shape=(256,256,3)\n",
        "img_in = Input(input_shape)              #input of model \n",
        "model = DenseNet121(include_top= False , # remove  the 3 fully-connected layers at the top of the network\n",
        "                weights='imagenet',      # pre train weight \n",
        "                input_tensor= img_in, \n",
        "                input_shape= input_shape,\n",
        "                pooling ='max') "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIxEIz4kZoe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, Dropout, Dense,Conv2D\n",
        "from keras.layers import BatchNormalization,Activation\n",
        "from keras.layers import MaxPooling2D,GlobalAveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import adam\n",
        "from keras import optimizers\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY30BUUaaCBH",
        "colab_type": "code",
        "outputId": "431f73dc-aeff-48bd-fc00-89e34b0c6788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15674
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 262, 262, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 128, 128, 64) 9408        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 128, 128, 64) 0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 130, 130, 64) 0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 64, 64, 64)   0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 64, 64, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 64, 64, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 64, 64, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 64, 64, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 64, 64, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 64, 64, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 64, 64, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 64, 64, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 64, 64, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 64, 64, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 64, 64, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 64, 64, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 64, 64, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 64, 64, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 64, 64, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 64, 64, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 64, 64, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 64, 64, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 64, 64, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 64, 64, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 64, 64, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 64, 64, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 64, 64, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 64, 64, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 64, 64, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 64, 64, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 32, 32, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 32, 32, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 32, 32, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 32, 32, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 32, 32, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 32, 32, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 32, 32, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 32, 32, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 32, 32, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 32, 32, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 32, 32, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 32, 32, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 32, 32, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 32, 32, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 32, 32, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 32, 32, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 32, 32, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 32, 32, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 32, 32, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 32, 32, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 32, 32, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 32, 32, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 32, 32, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 32, 32, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 32, 32, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 32, 32, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 32, 32, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 32, 32, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 32, 32, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 32, 32, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 32, 32, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 32, 32, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 32, 32, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 32, 32, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 32, 32, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 32, 32, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 32, 32, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 32, 32, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 32, 32, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 32, 32, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 32, 32, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 32, 32, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 32, 32, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 32, 32, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 32, 32, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 32, 32, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 32, 32, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 32, 32, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 32, 32, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 32, 32, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 32, 32, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 32, 32, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 32, 32, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 32, 32, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 32, 32, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 32, 32, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 32, 32, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 16, 16, 256)  0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 16, 16, 256)  1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 16, 16, 256)  0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 128)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 16, 16, 288)  0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 16, 16, 288)  1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 16, 16, 288)  0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 128)  36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 128)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 16, 16, 320)  0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 16, 16, 320)  1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 16, 16, 320)  0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 128)  40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 128)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 16, 16, 352)  0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 16, 16, 352)  1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 16, 16, 352)  0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 128)  45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 128)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 16, 16, 384)  0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 16, 16, 384)  1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 16, 16, 384)  0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 128)  49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 128)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 16, 16, 416)  0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 16, 16, 416)  1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 16, 16, 416)  0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 128)  53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 128)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 16, 16, 448)  0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 16, 16, 448)  1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 16, 16, 448)  0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 16, 16, 128)  57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 16, 16, 128)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 16, 16, 480)  0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 16, 16, 480)  1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 16, 16, 480)  0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 16, 16, 128)  61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 16, 16, 128)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 16, 16, 512)  0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 16, 16, 512)  0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 16, 16, 128)  65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 16, 16, 128)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 16, 16, 544)  0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 16, 16, 544)  2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 16, 16, 544)  0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 16, 16, 128)  69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 16, 16, 576)  0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 16, 16, 576)  2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 16, 16, 576)  0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 16, 16, 128)  73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 16, 16, 608)  0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 16, 16, 608)  2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 16, 16, 608)  0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 16, 16, 128)  77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 16, 16, 640)  0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 16, 16, 640)  2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 16, 16, 640)  0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 16, 16, 128)  81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 16, 16, 672)  0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 16, 16, 672)  2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 16, 16, 672)  0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 16, 16, 128)  86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 16, 16, 704)  0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 16, 16, 704)  2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 16, 16, 704)  0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 16, 16, 128)  90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 16, 16, 736)  0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 16, 16, 736)  2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 16, 16, 736)  0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 16, 16, 128)  94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 16, 16, 768)  0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 16, 16, 768)  3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 16, 16, 768)  0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 16, 16, 128)  98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 16, 16, 800)  0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 16, 16, 800)  3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 16, 16, 800)  0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 16, 16, 128)  102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 16, 16, 832)  0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 16, 16, 832)  3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 16, 16, 832)  0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 16, 16, 128)  106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 16, 16, 864)  0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 16, 16, 864)  3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 16, 16, 864)  0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 16, 16, 128)  110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 16, 16, 896)  0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 16, 16, 896)  3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 16, 16, 896)  0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 16, 16, 128)  114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 16, 16, 928)  0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 16, 16, 928)  3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 16, 16, 928)  0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 16, 16, 128)  118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 16, 16, 960)  0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 16, 16, 960)  3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 16, 16, 960)  0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 16, 16, 128)  122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 16, 16, 992)  0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 16, 16, 992)  3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 16, 16, 992)  0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 16, 16, 128)  126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 16, 16, 1024) 0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 16, 16, 1024) 4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 16, 16, 1024) 0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 16, 16, 512)  524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 8, 8, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 8, 8, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 8, 8, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 8, 8, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 8, 8, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 8, 8, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 8, 8, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 8, 8, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 8, 8, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 8, 8, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 8, 8, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 8, 8, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 8, 8, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 8, 8, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 8, 8, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 8, 8, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 8, 8, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 8, 8, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 8, 8, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 8, 8, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 8, 8, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 8, 8, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 8, 8, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 8, 8, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 8, 8, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 8, 8, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 8, 8, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 8, 8, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 8, 8, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 8, 8, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 8, 8, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 8, 8, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 8, 8, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 8, 8, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 8, 8, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 8, 8, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 8, 8, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 8, 8, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 8, 8, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 8, 8, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 8, 8, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 8, 8, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 8, 8, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 8, 8, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 8, 8, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 8, 8, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 8, 8, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 8, 8, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 8, 8, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 8, 8, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 8, 8, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 8, 8, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 8, 8, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 8, 8, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 8, 8, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 8, 8, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 8, 8, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 8, 8, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 8, 8, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 8, 8, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 8, 8, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 8, 8, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 8, 8, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 8, 8, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 8, 8, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 8, 8, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 8, 8, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 8, 8, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 8, 8, 1024)   0           bn[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "max_pool (GlobalMaxPooling2D)   (None, 1024)         0           relu[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 6,953,856\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOFACfC7aZnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ORGb2XalSP",
        "colab_type": "code",
        "outputId": "b5c099da-e784-4f55-a07e-2499e939f590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7293
        }
      },
      "source": [
        "\n",
        "# Check the trainable status of the individual layers\n",
        "for layer in model.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f5968774e48> True\n",
            "<keras.layers.convolutional.ZeroPadding2D object at 0x7f5914172588> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5914172400> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5912999630> True\n",
            "<keras.layers.core.Activation object at 0x7f5912999fd0> True\n",
            "<keras.layers.convolutional.ZeroPadding2D object at 0x7f59139f7c18> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f5913951668> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5912999f60> True\n",
            "<keras.layers.core.Activation object at 0x7f5913923f98> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59138d2f60> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5913849358> True\n",
            "<keras.layers.core.Activation object at 0x7f591385cfd0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59137e7358> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f59137fc358> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59137bd6a0> True\n",
            "<keras.layers.core.Activation object at 0x7f59137bd630> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59136f1860> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f591368a748> True\n",
            "<keras.layers.core.Activation object at 0x7f5913201fd0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f591326ed30> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f591324ec18> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f591364c4e0> True\n",
            "<keras.layers.core.Activation object at 0x7f59135e6c88> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59135813c8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5913598b70> True\n",
            "<keras.layers.core.Activation object at 0x7f5913558c88> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f591348ecc0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f5913445a90> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5913445dd8> True\n",
            "<keras.layers.core.Activation object at 0x7f5913466908> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59133dbb00> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59133b0cf8> True\n",
            "<keras.layers.core.Activation object at 0x7f5913370908> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59132857b8> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f5913199710> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5913199860> True\n",
            "<keras.layers.core.Activation object at 0x7f59131b8438> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59131327b8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59130ab668> True\n",
            "<keras.layers.core.Activation object at 0x7f5913044390> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5912fe1438> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f5912fb7390> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5912fb74e0> True\n",
            "<keras.layers.core.Activation object at 0x7f5912f58160> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5912ef0908> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5912e422e8> True\n",
            "<keras.layers.core.Activation object at 0x7f5912e65160> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5912dadfd0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f5912d91dd8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5912d52358> True\n",
            "<keras.layers.core.Activation object at 0x7f5912d52dd8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5912c87588> True\n",
            "<keras.layers.pooling.AveragePooling2D object at 0x7f5912c9cd30> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5912c5c390> True\n",
            "<keras.layers.core.Activation object at 0x7f5912bf2080> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5912bbcfd0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5912ba2dd8> True\n",
            "<keras.layers.core.Activation object at 0x7f5912b62dd8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f591294efd0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f5912aafb00> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5912804b38> True\n",
            "<keras.layers.core.Activation object at 0x7f591296cbe0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5912822240> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59128399e8> True\n",
            "<keras.layers.core.Activation object at 0x7f591277cb70> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5912712d68> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f59126e7978> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59126e7cc0> True\n",
            "<keras.layers.core.Activation object at 0x7f59126886a0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59125fca20> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59125f38d0> True\n",
            "<keras.layers.core.Activation object at 0x7f59125955f8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f591252c6a0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f59124845f8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5912484748> True\n",
            "<keras.layers.core.Activation object at 0x7f59124a3320> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59124136a0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f591238e518> True\n",
            "<keras.layers.core.Activation object at 0x7f59123b0240> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59122cb320> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f59122df320> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f591229a6d8> True\n",
            "<keras.layers.core.Activation object at 0x7f591229a668> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59041437f0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f590415c278> True\n",
            "<keras.layers.core.Activation object at 0x7f59041195c0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59017d6eb8> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f5904065cc0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f590176ef60> True\n",
            "<keras.layers.core.Activation object at 0x7f59017fada0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5901730278> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59016c40b8> True\n",
            "<keras.layers.core.Activation object at 0x7f5901683cf8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f590161dc88> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f59015f7e80> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59015f7f28> True\n",
            "<keras.layers.core.Activation object at 0x7f59015923c8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59014ffb00> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59014d1fd0> True\n",
            "<keras.layers.core.Activation object at 0x7f59014918d0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59014237b8> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f59013f96a0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59013f97f0> True\n",
            "<keras.layers.core.Activation object at 0x7f59013983c8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5901309780> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59012f8630> True\n",
            "<keras.layers.core.Activation object at 0x7f590129a358> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5901231400> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f5901220668> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5901187b38> True\n",
            "<keras.layers.core.Activation object at 0x7f59011a61d0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59010c1898> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59010db5c0> True\n",
            "<keras.layers.core.Activation object at 0x7f5901091710> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5900f80f60> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f5900fe1da0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5900f0dfd0> True\n",
            "<keras.layers.core.Activation object at 0x7f5900fa2d68> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5900eda550> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5900eeecf8> True\n",
            "<keras.layers.core.Activation object at 0x7f5900e25c88> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5900d9cf28> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f5900df89b0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5900dbd438> True\n",
            "<keras.layers.core.Activation object at 0x7f5900dbdb38> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5900d34208> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5900c87550> True\n",
            "<keras.layers.core.Activation object at 0x7f5900c48320> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5900bdd940> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f5900bb4898> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5900bb4d30> True\n",
            "<keras.layers.core.Activation object at 0x7f5900b525c0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5900ace940> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5900a437f0> True\n",
            "<keras.layers.core.Activation object at 0x7f5900a61518> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59009fa5c0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f5900950518> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5900950668> True\n",
            "<keras.layers.core.Activation object at 0x7f590096f240> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59008e35c0> True\n",
            "<keras.layers.pooling.AveragePooling2D object at 0x7f590085b470> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f590087a208> True\n",
            "<keras.layers.core.Activation object at 0x7f59007eec50> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5900796588> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5900764470> True\n",
            "<keras.layers.core.Activation object at 0x7f5900702240> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59006f9a20> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f59006b5240> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59006735f8> True\n",
            "<keras.layers.core.Activation object at 0x7f5900673fd0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f59005a86d8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59005bd160> True\n",
            "<keras.layers.core.Activation object at 0x7f590057ceb8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f590046acf8> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f5900448be0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59004094a8> True\n",
            "<keras.layers.core.Activation object at 0x7f59003a1a58> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5900341358> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f5900357b38> True\n",
            "<keras.layers.core.Activation object at 0x7f5900317c50> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f590024dc88> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f59002657f0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f59002267f0> True\n",
            "<keras.layers.core.Activation object at 0x7f5900226978> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f590019dac8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f590016cfd0> True\n",
            "<keras.layers.core.Activation object at 0x7f590012f8d0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f5900049780> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e3fd96d8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e3fd9828> True\n",
            "<keras.layers.core.Activation object at 0x7f58e3ffc400> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e3f76780> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e3e90358> True\n",
            "<keras.layers.core.Activation object at 0x7f58e3e44588> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e3e243c8> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e3df9320> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e3df9470> True\n",
            "<keras.layers.core.Activation object at 0x7f58e3d9a160> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e3d338d0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e3ccd5c0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e3c84710> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e3bf4f98> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e3bd4da0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e3b03fd0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e3b95d68> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e3aca550> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e3ae2cf8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e3a16c88> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e398df28> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e39ed9b0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e39b0438> True\n",
            "<keras.layers.core.Activation object at 0x7f58e39b0b38> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e3924208> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e38fa908> True\n",
            "<keras.layers.core.Activation object at 0x7f58e38bd358> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e37d1940> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e37a8898> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e37a8d30> True\n",
            "<keras.layers.core.Activation object at 0x7f58e37455c0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e373f908> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e36b07f0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e3650518> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e35ed5c0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e3542518> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e3542668> True\n",
            "<keras.layers.core.Activation object at 0x7f58e3564240> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e34d65c0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e3452438> True\n",
            "<keras.layers.core.Activation object at 0x7f58e3470208> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e33e59b0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e33a3240> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e33615f8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e3361fd0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e32946d8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e32aa0b8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e326aeb8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e3159cf8> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e31b7be0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e31794a8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e308fc50> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e30ad358> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e3042b38> True\n",
            "<keras.layers.core.Activation object at 0x7f58e2f9b978> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e30ec3c8> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e2f4f7f0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e2f117f0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e2f11978> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e2e86b00> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e2e5cfd0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e2e1f8d0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e2db67b8> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e2d076d8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e2d07828> True\n",
            "<keras.layers.core.Activation object at 0x7f58e2d28400> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e2ca1780> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e2c15630> True\n",
            "<keras.layers.core.Activation object at 0x7f58e2c3f358> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e2b52400> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e2b25358> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e2b254a8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e2ac8048> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e2a618d0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e2a795c0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e2a31710> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e2bf2a90> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e2901710> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e28affd0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e28c1d68> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e2878550> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e280fcf8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e2743c88> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e273bf28> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e27189b0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e26dc438> True\n",
            "<keras.layers.core.Activation object at 0x7f58e26dcb38> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e2652208> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e2626908> True\n",
            "<keras.layers.core.Activation object at 0x7f58e25e9358> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e257f940> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e24d8898> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e24d8d30> True\n",
            "<keras.layers.core.Activation object at 0x7f58e24f35c0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e246d940> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e23e17f0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e23ff518> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e231c5c0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e22ed518> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e22ed668> True\n",
            "<keras.layers.core.Activation object at 0x7f58e2293240> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e22055c0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e21fe438> True\n",
            "<keras.layers.core.Activation object at 0x7f58e219f208> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e21129b0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e20ce240> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e208d5f8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e208dfd0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e1fc2710> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e1fda0b8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e1f97eb8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e1e88cf8> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e1ee5be0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e1ea54a8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e1e3dc50> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e1dd9358> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e1defb38> True\n",
            "<keras.layers.core.Activation object at 0x7f58e1dafc18> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e1ce7c88> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e1cfd7f0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e1c407f0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e1c40978> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e1c39b00> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e1b8efd0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e1b4c8d0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e1d4b470> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e1ab76a0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e1ab77f0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e1a583c8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e19d0780> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e1944630> True\n",
            "<keras.layers.core.Activation object at 0x7f58e196b358> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e18fd400> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e1855358> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e18554a8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e1877048> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e1790898> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e17a85c0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e175f710> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e164bf60> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e16afda0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e15dffd0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e1670d68> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e15a7550> True\n",
            "<keras.layers.pooling.AveragePooling2D object at 0x7f58e15bccf8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e157c588> True\n",
            "<keras.layers.core.Activation object at 0x7f58e148dc88> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e14b4940> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e147f4a8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e1422278> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e13938d0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e1352198> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e13105f8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e1310fd0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e1244748> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e125a1d0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e121cfd0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e1107d30> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e1166c18> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e11234e0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e10bda90> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e105f3c8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e1073b70> True\n",
            "<keras.layers.core.Activation object at 0x7f58e1099400> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e0faf358> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e0f02828> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e0ec47f0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e0ec4978> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e0ebab38> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e0e0fcf8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e0dcf908> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e0d647b8> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e0d38710> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e0d38860> True\n",
            "<keras.layers.core.Activation object at 0x7f58e0cd8438> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e0c53780> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e0bcd668> True\n",
            "<keras.layers.core.Activation object at 0x7f58e0be7390> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e0b7f438> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e0ad4390> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e0ad44e0> True\n",
            "<keras.layers.core.Activation object at 0x7f58e0af8160> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e0a0f908> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e0a285f8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e09e2748> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e08cffd0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e0932dd8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e08f2358> True\n",
            "<keras.layers.core.Activation object at 0x7f58e08f2dd8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e082b550> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e07c0d30> True\n",
            "<keras.layers.core.Activation object at 0x7f58e0773cc0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e06ebf60> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e06cb9e8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e06fc470> True\n",
            "<keras.layers.core.Activation object at 0x7f58e06fcb70> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e05f6d68> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e05d7940> True\n",
            "<keras.layers.core.Activation object at 0x7f58e059c940> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e052f940> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e04838d0> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e0483d68> True\n",
            "<keras.layers.core.Activation object at 0x7f58e04a25f8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e041b978> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e038f828> True\n",
            "<keras.layers.core.Activation object at 0x7f58e03af550> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e02c85f8> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e029e3c8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e029e550> True\n",
            "<keras.layers.core.Activation object at 0x7f58e02bc240> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e02325f8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e01aa4a8> True\n",
            "<keras.layers.core.Activation object at 0x7f58e014e278> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58e00c09b0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58e00fc278> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58e00bb630> True\n",
            "<keras.layers.core.Activation object at 0x7f58e00bb5c0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58dfff2748> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58dff891d0> True\n",
            "<keras.layers.core.Activation object at 0x7f58dff48fd0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58dfeb5d30> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58dfe93c18> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58dfe512e8> True\n",
            "<keras.layers.core.Activation object at 0x7f58dfdebc50> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58dfd8c128> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58dfda0b70> True\n",
            "<keras.layers.core.Activation object at 0x7f58dfd63c88> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58dfc96cc0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58dfcab828> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58dfc70828> True\n",
            "<keras.layers.core.Activation object at 0x7f58dfc709b0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58dfbe4b38> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58dfbb9cf8> True\n",
            "<keras.layers.core.Activation object at 0x7f58dfb7a908> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58dfa927b8> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58dfa66710> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58dfa66860> True\n",
            "<keras.layers.core.Activation object at 0x7f58dfa06438> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58df980780> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58df979668> True\n",
            "<keras.layers.core.Activation object at 0x7f58df912390> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58df8ac438> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58df801390> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58df8014e0> True\n",
            "<keras.layers.core.Activation object at 0x7f58df823160> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58df7bd908> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58df757cc0> True\n",
            "<keras.layers.core.Activation object at 0x7f58df70d6d8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58df67dfd0> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58df660dd8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58df58efd0> True\n",
            "<keras.layers.core.Activation object at 0x7f58df61fdd8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58df553550> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58df569d30> True\n",
            "<keras.layers.core.Activation object at 0x7f58df4a0cc0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f58df416f60> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f58df4769e8> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f58df439470> True\n",
            "<keras.layers.core.Activation object at 0x7f58df439b70> True\n",
            "<keras.layers.pooling.GlobalMaxPooling2D object at 0x7f58df36af60> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7XTS7O4PSri",
        "colab_type": "code",
        "outputId": "6ab40a93-4ad5-46d7-e0df-aaa088cf1e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# Create the model\n",
        "model_Densenet = Sequential()\n",
        " \n",
        "# Add the vgg convolutional base model\n",
        "model_Densenet.add(model)\n",
        " \n",
        "# Add new layers\n",
        "#model_vgg_flow.add(Flatten())\n",
        "model_Densenet.add(Dense(256, activation='relu'))\n",
        "model_Densenet.add(Dropout(0.25))\n",
        "model_Densenet.add(Dense(128, activation='relu'))\n",
        "model_Densenet.add(Dropout(0.35))\n",
        "model_Densenet.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#model_vgg_flow.add(Dense(1, activation='softmax')) \n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "model_Densenet.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet121 (Model)          (None, 1024)              7037504   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 7,332,929\n",
            "Trainable params: 7,249,281\n",
            "Non-trainable params: 83,648\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2IUY9oUbqmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam=optimizers.Adam(lr=0.0001)\n",
        "model_Densenet.compile(optimizer=adam,loss='binary_crossentropy',metrics=[keras.metrics.binary_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSV4uKZxPSt8",
        "colab_type": "code",
        "outputId": "d6cb86c0-42cd-4db0-f60d-84a7384521fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4848
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/RSNA/first_try_1.h5', monitor='val_loss',verbose=1,save_best_only=True, save_weights_only=True,mode='val_acc')\n",
        "batch_size=128\n",
        "model_Densenet.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=4800// batch_size,\n",
        "        epochs=70,\n",
        "        validation_data=validation_generator,callbacks=[checkpointer],\n",
        "        validation_steps=440 // batch_size)\n",
        "#model_Densenet.save_weights('/content/drive/My Drive/RSNA/first_try.h5')  # always save your weights after training or during training"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:407: RuntimeWarning: ModelCheckpoint mode val_acc is unknown, fallback to auto mode.\n",
            "  RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.4148 - binary_accuracy: 0.8345 - val_loss: 0.5469 - val_binary_accuracy: 0.7317\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.54687, saving model to /content/drive/My Drive/RSNA/first_try_1.h5\n",
            "Epoch 2/70\n",
            "37/37 [==============================] - 12s 337ms/step - loss: 0.4220 - binary_accuracy: 0.8057 - val_loss: 0.6016 - val_binary_accuracy: 0.6458\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.54687\n",
            "Epoch 3/70\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.4184 - binary_accuracy: 0.8176 - val_loss: 0.5563 - val_binary_accuracy: 0.6667\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.54687\n",
            "Epoch 4/70\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.3921 - binary_accuracy: 0.8333 - val_loss: 0.4669 - val_binary_accuracy: 0.7708\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.54687 to 0.46686, saving model to /content/drive/My Drive/RSNA/first_try_1.h5\n",
            "Epoch 5/70\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.3348 - binary_accuracy: 0.8429 - val_loss: 0.7020 - val_binary_accuracy: 0.7708\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.46686\n",
            "Epoch 6/70\n",
            "37/37 [==============================] - 12s 332ms/step - loss: 0.3884 - binary_accuracy: 0.8193 - val_loss: 0.3317 - val_binary_accuracy: 0.8333\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.46686 to 0.33173, saving model to /content/drive/My Drive/RSNA/first_try_1.h5\n",
            "Epoch 7/70\n",
            "37/37 [==============================] - 12s 336ms/step - loss: 0.3893 - binary_accuracy: 0.8226 - val_loss: 0.5273 - val_binary_accuracy: 0.6875\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.33173\n",
            "Epoch 8/70\n",
            "37/37 [==============================] - 13s 339ms/step - loss: 0.4065 - binary_accuracy: 0.8226 - val_loss: 0.5623 - val_binary_accuracy: 0.6667\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.33173\n",
            "Epoch 9/70\n",
            "37/37 [==============================] - 12s 335ms/step - loss: 0.4144 - binary_accuracy: 0.8193 - val_loss: 0.5261 - val_binary_accuracy: 0.7708\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.33173\n",
            "Epoch 10/70\n",
            "37/37 [==============================] - 12s 336ms/step - loss: 0.3796 - binary_accuracy: 0.8294 - val_loss: 0.5511 - val_binary_accuracy: 0.7292\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.33173\n",
            "Epoch 11/70\n",
            "37/37 [==============================] - 12s 330ms/step - loss: 0.4189 - binary_accuracy: 0.8142 - val_loss: 0.4811 - val_binary_accuracy: 0.7805\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.33173\n",
            "Epoch 12/70\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.3808 - binary_accuracy: 0.8175 - val_loss: 0.6751 - val_binary_accuracy: 0.5625\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.33173\n",
            "Epoch 13/70\n",
            "37/37 [==============================] - 12s 334ms/step - loss: 0.4050 - binary_accuracy: 0.8142 - val_loss: 0.5703 - val_binary_accuracy: 0.7708\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.33173\n",
            "Epoch 14/70\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.4095 - binary_accuracy: 0.8209 - val_loss: 0.4249 - val_binary_accuracy: 0.8125\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.33173\n",
            "Epoch 15/70\n",
            "37/37 [==============================] - 12s 337ms/step - loss: 0.3919 - binary_accuracy: 0.8041 - val_loss: 0.8107 - val_binary_accuracy: 0.6458\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.33173\n",
            "Epoch 16/70\n",
            "37/37 [==============================] - 12s 335ms/step - loss: 0.3219 - binary_accuracy: 0.8682 - val_loss: 0.3432 - val_binary_accuracy: 0.8958\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.33173\n",
            "Epoch 17/70\n",
            "37/37 [==============================] - 12s 332ms/step - loss: 0.3670 - binary_accuracy: 0.8345 - val_loss: 0.4155 - val_binary_accuracy: 0.7917\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.33173\n",
            "Epoch 18/70\n",
            "37/37 [==============================] - 12s 334ms/step - loss: 0.3899 - binary_accuracy: 0.8378 - val_loss: 0.6337 - val_binary_accuracy: 0.7292\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.33173\n",
            "Epoch 19/70\n",
            "37/37 [==============================] - 12s 337ms/step - loss: 0.4226 - binary_accuracy: 0.8142 - val_loss: 0.5526 - val_binary_accuracy: 0.7917\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.33173\n",
            "Epoch 20/70\n",
            "37/37 [==============================] - 12s 336ms/step - loss: 0.3922 - binary_accuracy: 0.8226 - val_loss: 0.4595 - val_binary_accuracy: 0.8049\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.33173\n",
            "Epoch 21/70\n",
            "37/37 [==============================] - 12s 337ms/step - loss: 0.3625 - binary_accuracy: 0.8509 - val_loss: 0.6369 - val_binary_accuracy: 0.6667\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.33173\n",
            "Epoch 22/70\n",
            "37/37 [==============================] - 13s 343ms/step - loss: 0.3373 - binary_accuracy: 0.8395 - val_loss: 0.5135 - val_binary_accuracy: 0.7500\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.33173\n",
            "Epoch 23/70\n",
            "37/37 [==============================] - 12s 337ms/step - loss: 0.3658 - binary_accuracy: 0.8361 - val_loss: 0.5652 - val_binary_accuracy: 0.7292\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.33173\n",
            "Epoch 24/70\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.3776 - binary_accuracy: 0.8328 - val_loss: 0.4877 - val_binary_accuracy: 0.8125\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.33173\n",
            "Epoch 25/70\n",
            "37/37 [==============================] - 12s 331ms/step - loss: 0.3841 - binary_accuracy: 0.8209 - val_loss: 0.6763 - val_binary_accuracy: 0.6042\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.33173\n",
            "Epoch 26/70\n",
            "37/37 [==============================] - 12s 334ms/step - loss: 0.3850 - binary_accuracy: 0.8226 - val_loss: 0.4845 - val_binary_accuracy: 0.8125\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.33173\n",
            "Epoch 27/70\n",
            "37/37 [==============================] - 12s 329ms/step - loss: 0.3737 - binary_accuracy: 0.8311 - val_loss: 0.6051 - val_binary_accuracy: 0.7292\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.33173\n",
            "Epoch 28/70\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.3593 - binary_accuracy: 0.8429 - val_loss: 0.4401 - val_binary_accuracy: 0.7917\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.33173\n",
            "Epoch 29/70\n",
            "37/37 [==============================] - 12s 329ms/step - loss: 0.3926 - binary_accuracy: 0.8475 - val_loss: 0.4640 - val_binary_accuracy: 0.7073\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.33173\n",
            "Epoch 30/70\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.3844 - binary_accuracy: 0.8429 - val_loss: 0.3971 - val_binary_accuracy: 0.8750\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.33173\n",
            "Epoch 31/70\n",
            "37/37 [==============================] - 12s 330ms/step - loss: 0.3406 - binary_accuracy: 0.8480 - val_loss: 0.3221 - val_binary_accuracy: 0.8333\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.33173 to 0.32214, saving model to /content/drive/My Drive/RSNA/first_try_1.h5\n",
            "Epoch 32/70\n",
            "37/37 [==============================] - 12s 336ms/step - loss: 0.3555 - binary_accuracy: 0.8632 - val_loss: 0.5897 - val_binary_accuracy: 0.6667\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.32214\n",
            "Epoch 33/70\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.4136 - binary_accuracy: 0.8226 - val_loss: 0.5936 - val_binary_accuracy: 0.6875\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.32214\n",
            "Epoch 34/70\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.3573 - binary_accuracy: 0.8480 - val_loss: 0.4605 - val_binary_accuracy: 0.7083\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.32214\n",
            "Epoch 35/70\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.3732 - binary_accuracy: 0.8345 - val_loss: 0.6922 - val_binary_accuracy: 0.6250\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.32214\n",
            "Epoch 36/70\n",
            "37/37 [==============================] - 12s 329ms/step - loss: 0.3536 - binary_accuracy: 0.8395 - val_loss: 0.8909 - val_binary_accuracy: 0.6667\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.32214\n",
            "Epoch 37/70\n",
            "37/37 [==============================] - 12s 323ms/step - loss: 0.3935 - binary_accuracy: 0.8316 - val_loss: 0.4574 - val_binary_accuracy: 0.8125\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.32214\n",
            "Epoch 38/70\n",
            "37/37 [==============================] - 12s 332ms/step - loss: 0.3418 - binary_accuracy: 0.8581 - val_loss: 0.4975 - val_binary_accuracy: 0.7500\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.32214\n",
            "Epoch 39/70\n",
            "37/37 [==============================] - 12s 332ms/step - loss: 0.3672 - binary_accuracy: 0.8209 - val_loss: 0.5311 - val_binary_accuracy: 0.7805\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.32214\n",
            "Epoch 40/70\n",
            "37/37 [==============================] - 12s 328ms/step - loss: 0.3201 - binary_accuracy: 0.8598 - val_loss: 0.4092 - val_binary_accuracy: 0.8750\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.32214\n",
            "Epoch 41/70\n",
            "37/37 [==============================] - 12s 328ms/step - loss: 0.3196 - binary_accuracy: 0.8682 - val_loss: 0.6905 - val_binary_accuracy: 0.7708\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.32214\n",
            "Epoch 42/70\n",
            "37/37 [==============================] - 12s 331ms/step - loss: 0.3529 - binary_accuracy: 0.8598 - val_loss: 0.3134 - val_binary_accuracy: 0.8750\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.32214 to 0.31345, saving model to /content/drive/My Drive/RSNA/first_try_1.h5\n",
            "Epoch 43/70\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.3560 - binary_accuracy: 0.8514 - val_loss: 0.4236 - val_binary_accuracy: 0.7917\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.31345\n",
            "Epoch 44/70\n",
            "37/37 [==============================] - 12s 332ms/step - loss: 0.3308 - binary_accuracy: 0.8514 - val_loss: 0.5695 - val_binary_accuracy: 0.7500\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.31345\n",
            "Epoch 45/70\n",
            "37/37 [==============================] - 12s 324ms/step - loss: 0.2964 - binary_accuracy: 0.8807 - val_loss: 0.6328 - val_binary_accuracy: 0.7917\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.31345\n",
            "Epoch 46/70\n",
            "37/37 [==============================] - 12s 335ms/step - loss: 0.3186 - binary_accuracy: 0.8564 - val_loss: 0.6350 - val_binary_accuracy: 0.7083\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.31345\n",
            "Epoch 47/70\n",
            "37/37 [==============================] - 13s 339ms/step - loss: 0.3043 - binary_accuracy: 0.8666 - val_loss: 0.5539 - val_binary_accuracy: 0.7083\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.31345\n",
            "Epoch 48/70\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.3139 - binary_accuracy: 0.8530 - val_loss: 0.5237 - val_binary_accuracy: 0.7317\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.31345\n",
            "Epoch 49/70\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.3640 - binary_accuracy: 0.8361 - val_loss: 0.5947 - val_binary_accuracy: 0.7083\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.31345\n",
            "Epoch 50/70\n",
            "37/37 [==============================] - 12s 332ms/step - loss: 0.2988 - binary_accuracy: 0.8615 - val_loss: 0.5157 - val_binary_accuracy: 0.7708\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.31345\n",
            "Epoch 51/70\n",
            "37/37 [==============================] - 12s 330ms/step - loss: 0.3060 - binary_accuracy: 0.8632 - val_loss: 0.3494 - val_binary_accuracy: 0.7917\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.31345\n",
            "Epoch 52/70\n",
            "37/37 [==============================] - 12s 328ms/step - loss: 0.3334 - binary_accuracy: 0.8615 - val_loss: 0.8210 - val_binary_accuracy: 0.6875\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.31345\n",
            "Epoch 53/70\n",
            "37/37 [==============================] - 12s 328ms/step - loss: 0.3318 - binary_accuracy: 0.8682 - val_loss: 0.5525 - val_binary_accuracy: 0.7708\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.31345\n",
            "Epoch 54/70\n",
            "37/37 [==============================] - 12s 336ms/step - loss: 0.2976 - binary_accuracy: 0.8564 - val_loss: 0.4017 - val_binary_accuracy: 0.8542\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.31345\n",
            "Epoch 55/70\n",
            "37/37 [==============================] - 12s 337ms/step - loss: 0.2869 - binary_accuracy: 0.8750 - val_loss: 0.6624 - val_binary_accuracy: 0.7292\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.31345\n",
            "Epoch 56/70\n",
            "37/37 [==============================] - 12s 332ms/step - loss: 0.3375 - binary_accuracy: 0.8497 - val_loss: 0.5550 - val_binary_accuracy: 0.7292\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.31345\n",
            "Epoch 57/70\n",
            "37/37 [==============================] - 12s 328ms/step - loss: 0.3118 - binary_accuracy: 0.8682 - val_loss: 0.4907 - val_binary_accuracy: 0.8293\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.31345\n",
            "Epoch 58/70\n",
            "37/37 [==============================] - 12s 331ms/step - loss: 0.3356 - binary_accuracy: 0.8530 - val_loss: 0.4668 - val_binary_accuracy: 0.7708\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.31345\n",
            "Epoch 59/70\n",
            "37/37 [==============================] - 12s 331ms/step - loss: 0.2933 - binary_accuracy: 0.8750 - val_loss: 0.4542 - val_binary_accuracy: 0.7500\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.31345\n",
            "Epoch 60/70\n",
            "37/37 [==============================] - 12s 330ms/step - loss: 0.3288 - binary_accuracy: 0.8547 - val_loss: 0.6196 - val_binary_accuracy: 0.7292\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.31345\n",
            "Epoch 61/70\n",
            "37/37 [==============================] - 12s 329ms/step - loss: 0.3141 - binary_accuracy: 0.8580 - val_loss: 0.6114 - val_binary_accuracy: 0.7292\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.31345\n",
            "Epoch 62/70\n",
            "37/37 [==============================] - 12s 335ms/step - loss: 0.3286 - binary_accuracy: 0.8682 - val_loss: 0.8776 - val_binary_accuracy: 0.6458\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.31345\n",
            "Epoch 63/70\n",
            "37/37 [==============================] - 12s 327ms/step - loss: 0.2854 - binary_accuracy: 0.8801 - val_loss: 0.5773 - val_binary_accuracy: 0.8542\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.31345\n",
            "Epoch 64/70\n",
            "37/37 [==============================] - 12s 329ms/step - loss: 0.2745 - binary_accuracy: 0.9003 - val_loss: 0.6891 - val_binary_accuracy: 0.7708\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.31345\n",
            "Epoch 65/70\n",
            "37/37 [==============================] - 12s 331ms/step - loss: 0.3373 - binary_accuracy: 0.8480 - val_loss: 0.5221 - val_binary_accuracy: 0.7917\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.31345\n",
            "Epoch 66/70\n",
            "37/37 [==============================] - 12s 329ms/step - loss: 0.3346 - binary_accuracy: 0.8480 - val_loss: 0.6728 - val_binary_accuracy: 0.7292\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.31345\n",
            "Epoch 67/70\n",
            "37/37 [==============================] - 12s 331ms/step - loss: 0.3582 - binary_accuracy: 0.8311 - val_loss: 0.5306 - val_binary_accuracy: 0.6829\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.31345\n",
            "Epoch 68/70\n",
            "37/37 [==============================] - 12s 330ms/step - loss: 0.3390 - binary_accuracy: 0.8412 - val_loss: 0.4618 - val_binary_accuracy: 0.8125\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.31345\n",
            "Epoch 69/70\n",
            "37/37 [==============================] - 12s 327ms/step - loss: 0.3116 - binary_accuracy: 0.8885 - val_loss: 0.5381 - val_binary_accuracy: 0.7292\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.31345\n",
            "Epoch 70/70\n",
            "37/37 [==============================] - 12s 323ms/step - loss: 0.2294 - binary_accuracy: 0.9003 - val_loss: 0.4860 - val_binary_accuracy: 0.8333\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.31345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff912410358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEOi30Q-zmu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dir=os.listdir('/content/drive/My Drive/validation_png/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtpNhtSe21LU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1e22256-2b18-4998-f21a-c0c9f286b243"
      },
      "source": [
        "Dir"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['validation_pneumonia', 'validation_normal']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-ngQSFZ21WK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4pl2yp421H9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG7puTwD21D-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6-8Jgo1zm4d",
        "colab_type": "code",
        "outputId": "071cfa4b-0816-49d6-dbbe-1d3f30bdea45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import os\n",
        "import cv2 \n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "patientID=[]\n",
        "filename=[]\n",
        "ValDir= '/content/drive/My Drive/validation_png/'\n",
        "\n",
        "# loop over the input images\n",
        "dirs = os.listdir(ValDir) \n",
        "for dir in dirs:\n",
        "    absDirPath = os.path.join(os.path.sep,ValDir, dir)\n",
        "    images = os.listdir(absDirPath)\n",
        "    for imageFileName in images:\n",
        "        \n",
        "        # load the image, pre-process it, and store it in the data list\n",
        "        imageFullPath = os.path.join(ValDir, dir, imageFileName)\n",
        "        #print(imageFullPath)\n",
        "        img = load_img(imageFullPath)\n",
        "        arr = img_to_array(img)  #Numpy array with shape (233,233,3)\n",
        "        arr = cv2.resize(arr, (256,256)) #Numpy array with shape (HEIGHT, WIDTH,3)\n",
        "        #print(arr.shape)\n",
        "        data.append(arr)\n",
        "        patientID.append(imageFileName.split('/')[-1].split('.')[0])\n",
        "        #print(patientID)\n",
        "        filename.append(imageFullPath)\n",
        "        \n",
        "        #label = classes_to_int(dir)\n",
        "        if(dir== 'validation_pneumonia'):\n",
        "          label=1\n",
        "        else:\n",
        "          label=0\n",
        "        #print(label)\n",
        "        labels.append(label)\n",
        "\n",
        "\n",
        "print(len(images))\n",
        "print('Number of images :-',len(data))\n",
        "print('Number of Labels',len(labels))\n",
        "print('Number of patientID :-',len(patientID))\n",
        "print(len(filename))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250\n",
            "Number of images :- 441\n",
            "Number of Labels 441\n",
            "Number of patientID :- 441\n",
            "441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnMHsKkjzm8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Valid_df = pd.DataFrame({ \n",
        "                        'patientId':patientID,\n",
        "                       'images':data,\n",
        "                        'Labels': labels,\n",
        "                         'Filenames':filename\n",
        "                         })\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtvCbd4xzmom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model_Densenet.load_weights(\"/content/drive/My Drive/RSNA/first_try.h5\")\n",
        "y_preds=[]\n",
        "for img in Valid_df['images']:\n",
        "  img=img.reshape(-1,256,256,3)\n",
        "  pred_1=model_Densenet.predict(img)\n",
        "  y_preds.append(pred_1)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xty8qxc9HuJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Valid_df['preds']=preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIo2wjpgHzz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b9d6a756-ae1e-48b4-e56c-7041ebb9b095"
      },
      "source": [
        "Valid_df['Labels'].value_counts()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    250\n",
              "1    191\n",
              "Name: Labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ92Qqmr_I_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_preds_1=y_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ios1E40_8GAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds=[]\n",
        "for i, predicted in enumerate(y_preds_1):\n",
        "  if (predicted[0][0])>=0.4:\n",
        "    value=1\n",
        "    preds.append(value)\n",
        "      \n",
        "    \n",
        "  else :\n",
        "    value=0\n",
        "    preds.append(value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnutrg-YC-54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_val=Valid_df['Labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsmIx7pG8Pud",
        "colab_type": "code",
        "outputId": "9cc980ca-b211-4165-db8e-021b59f27c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "print(\"\\nConfusion_Marix is :\\n\",confusion_matrix(y_val, preds))\n",
        "print(\"\\nClassification_Report is :\\n\",classification_report(y_val,preds))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion_Marix is :\n",
            " [[ 54 196]\n",
            " [ 43 148]]\n",
            "\n",
            "Classification_Report is :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.22      0.31       250\n",
            "           1       0.43      0.77      0.55       191\n",
            "\n",
            "    accuracy                           0.46       441\n",
            "   macro avg       0.49      0.50      0.43       441\n",
            "weighted avg       0.50      0.46      0.42       441\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH6nOyLH8PrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8e2da589-40f2-409f-b008-3c0c7b6dd7cc"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_val, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcTfX/wPHX2zAz9oRvZM++i8lS\nCRGS0iJLyL6UokW/lBZpkbTbt5IUoZSkULbIkp0ZsoZBtuy7mffvj3Mmt2mWi7lzZnk/H4/7cM85\nn3PO+37cOe/7+ZxzPkdUFWOMMSY+GbwOwBhjTMpmicIYY0yCLFEYY4xJkCUKY4wxCbJEYYwxJkGW\nKIwxxiTIEoXxm4i0EZE5XseRkojIKRG5yYP9FhURFZGMyb3vQBCRcBGpexXr2XcyGViiSKVE5E8R\nOeseqP4SkfEiki2Q+1TVL1S1YSD34UtEbhWReSJyUkSOi8j3IlIuufYfRzwLRKSL7zxVzaaqOwK0\nv1IiMlVEDruff72IPCMiQYHY39VyE1aJa9mGqpZX1QWJ7Oc/yTG5v5PplSWK1O1eVc0GVAFuBl7w\nOJ6rEtevYhGpBcwBvgNuBIoB64AlgfgFn9J+mYtIcWA5sAeoqKo5gYeBMCB7Eu/Ls8+e0urdxENV\n7ZUKX8CfQAOf6XeAH3ymQ4B3gd3AAWAkkNlneTNgLXAC2A40dufnBMYB+4G9wBtAkLusA7DYfT8C\neDdWTN8Bz7jvbwS+Bg4BO4FePuX6A9OAie7+u8Tx+X4Fhscx/0dggvu+LhAJvAgcduukjT914LPu\n88BfwOdALmCmG/NR931Bt/ybQBRwDjgFDHXnK1DCfT8eGAb8AJzEOdAX94mnIfAHcBwYDiyM67O7\nZSf6/n/Gsbyou+/27uc7DPTzWV4dWAocc/8vhwLBPssV6AlsBXa68z7CSUwngFVAbZ/yQW49b3c/\n2yqgELDI3dZpt15auuWb4ny/jgG/AZVifXefB9YD54GM+Hyf3dhXunEcAN535+9293XKfdXC5zvp\nlikPzAX+dtd90eu/1bTw8jwAe13lf9y//7AKAhuAj3yWfwDMAK7H+QX6PTDQXVbdPVjdhdOqLACU\ncZdNB0YBWYH/ASuA7u6yf/4ogTvcg4q407mAszgJIoN7IHkFCAZuAnYAjdyy/YGLwP1u2cyxPlsW\nnINyvTg+d0dgv/u+LnAJeB8nKdRxD1il/aiDmHUHuetmBnIDD7n7zw5MBb712fcCYh3Y+W+iOOLW\nb0bgC2CyuyyPe+B70F3W262D+BLFX0DHBP7/i7r7HuPGXhnnoFvWXV4NqOnuqyiwCXgqVtxz3bqJ\nSZ5t3TrICDzrxhDqLnsO5ztWGhB3f7lj14E7fTNwEKiBk2Da43xfQ3y+u2txEk1mn3kx3+elQDv3\nfTagZqzPnNFnXx24/J3MjpMUnwVC3ekaXv+tpoWX5wHY6yr/45w/rFM4v+4U+AW4zl0mOAdM31+z\ntbj8y3EU8EEc27zBPdj4tjxaA/Pd975/lILzC+8Od7orMM99XwPYHWvbLwCfuu/7A4sS+GwF3c9U\nJo5ljYGL7vu6OAf7rD7LpwAv+1EHdYELMQfCeOKoAhz1mV5A4olirM+yJsBm9/2jwFKfZYKTaONL\nFBdxW3nxLI85aBb0mbcCaBVP+aeA6bHivjOR79hRoLL7/g+gWTzlYieKEcDrscr8AdTx+e52iuP7\nHJMoFgGvAXni+czxJYrWwJpA/t2l15f1D6Zu96vqzyJSB/gS51frMSAvzq/iVSISU1Zwft2B80tu\nVhzbKwJkAvb7rJcB54D2L6qqIjIZ549zEfAITndJzHZuFJFjPqsE4XQnxfjPNn0cBaKB/MDmWMvy\n43Sz/FNWVU/7TO/CadUkVgcAh1T13D8LRbLgtEIa47SQALKLSJCqRiUQr6+/fN6fwflFjBvTP5/Z\nrb/IBLZzBOezXtX+RKQUTksrDKceMuK08nz96/9ARPoAnd1YFciB850C5zuz3Y94wPn/by8iT/rM\nC3a3G+e+Y+kMDAA2i8hO4DVVnenHfq8kRnMF7GR2GqCqC3F+zb7rzjqM0w1UXlWvc1851TnxDc4f\nafE4NrUHp0WRx2e9HKpaPp5dTwKai0gRnFbE1z7b2emzjetUNbuqNvENO4HPcxqn++HhOBa3wGk9\nxcglIll9pgsD+/yog7hieBana6WGqubA6V4DJ8EkGLMf9uO0lJwNOtmrYPzF+RmnG+xqjcBJsiXd\nz/Iilz9HjH8+j4jUBv4Pp35zqep1ON2TMevE952Jyx7gzVj//1lUdVJc+45NVbeqamucrs9BwDT3\n/zix+t+D081pkpglirTjQ+AuEamsqtE4fdcfiMj/AESkgIg0csuOAzqKSH0RyeAuK6Oq+3GuNHpP\nRHK4y4q7LZb/UNU1OAfkscBsVY1pQawATorI8yKSWUSCRKSCiNxyBZ+nL86v0l4ikl1EconIGzjd\nR6/FKvuaiAS7B7umwFQ/6iAu2XGSyzERuR54NdbyA1z9gegHoKKI3O9e6dMTyJdA+VeBW0VksIjk\nc+MvISITReQ6P/aXHeecyCkRKQM85kf5Szgn8jOKyCs4LYoYY4HXRaSkOCqJSG53Wex6GQP0EJEa\nbtmsInKPiPh1tZaItBWRvO7/Ycx3KtqNLZr4/w9mAvlF5CkRCXG/NzX82adJmCWKNEJVDwETcE4g\ng3NVyTZgmYicwPmFWtotuwLnpPAHOL8aF+J0F4DTlx4MROB0AU0j4S6QL4EG7r8xsUThHLCr4Fzx\nFJNMcl7B51kMNMI5+bsfp0vpZuB2Vd3qU/QvN859OCePe6hqTHdVvHUQjw9xTgwfBpYBP8Va/hFO\nC+qoiHzs72dxP89hnBbSOzjdSuVwruw5H0/57ThJsSgQLiLHcVpsK3HOSyWmD0534EmcA/dXiZSf\njfN5t+DU9Tn+3T30Ps75nzk4CWgcTl2Bc87pMxE5JiItVHUlzjmroTj/N9twziX4qzHOZz6FU+et\nVPWsqp7Bufpsibuvmr4rqepJnAs07sX5XmwF6l3Bfk08Yq5YMSbVce/knaiqCXXhpEgikgHn8tw2\nqjrf63iMSYi1KIxJJiLSSESuE5EQLp8zWOZxWMYkKmCJQkQ+EZGDIrIxnuUiIh+LyDZ3aIKqgYrF\nmBSiFs5VOYdxukfuV9Wz3oZkTOIC1vUkInfgXOc/QVUrxLG8CfAkzrXmNXBuFrMTT8YYk8IErEWh\nqotwbqOPTzOcJKKqugy4TkT8uW7cGGNMMvLyhrsC/Puqikh33v7YBUWkG9ANIGvWrNXKlCmTLAEa\nY0xqFhUFZzbtIvT8MdZz6bCq5r2a7aSKO7NVdTQwGiAsLExXrlzpcUTGGJOCqTJ3LnTuItx7YQQP\n1j5Ig1/777razXl51dNenFvuYxR05xljjLlKp7fsZX2xZoxv9CVZs0L7ZY9Rf1Hse0evjJeJYgbw\nqHv1U03guHtnsDHGmCulypbnxhBdphwldv3MAw1OsXo1VK9+7ZsOWNeTiEzCGaEzjzv42as4A86h\nqiNxBqVrgnPX5hmcO4WNMcZcoXPh29lzd1dK7ZnP0tB6ZBo/huYt/R2aK3EBSxTuoF4JLY95cIox\nxpirtHw5THhwA2/tW8WXdUfT7PsuZM0We/zHa2N3ZhtjTCp0YfVGpjSdwK23wsyM97P26x08Mr9r\nkicJsERhjDGpy4UL7O/eHwmrSq0f+tG13Tk2bIA6D+ZOfN2rlCoujzXGGAOXlizn7wc6k/9QONMy\ntyXnuA8Y2To04Pu1RGGMManAH/P2clOD2pzXG3i37kw6fX0P11+fPPu2ridjjEnBojZtYdAgqHR3\nAbpm/4q1E8PpMz/5kgRYojDGmJTp2DGOteyGlCvDD30Xce+9MHjbA9zbJkfi6yYx63oyxpgUJvrb\nGZzp8BjZj//FkJDneGLULTz8KEjSX9DkF0sUxhiTgpxs2YXsU8axg4p8evt3/N+UMPJ7PK62JQpj\njPGaKqoweowQ8W0YeUOKUGjI87zfJdizVoQvSxTGGOOlPXs426EHQw624vmN7WjQoAfjxkHhwl4H\ndpmdzDbGGC9ER6PDR3ChVHmi5y1g15bzDB8Oc+akrCQB1qIwxpjkt3UrFx7tQvCyRSykAWNvGc3A\nycW46SavA4ubtSiMMSaZ/To6gjPL19Mt4yeEvz+HSctSbpIAa1EYY0zyWLeOk7+upfOi9kyd2owG\n1XYw9ItclC7tdWCJs0RhjDGBdP48vPEG0QPf5rjm58cMLRk4MJQ+fXKRMZUcgVNJmMYYkwotXUpU\nh84EbdnE5zzK+Irv89sXoVSs6HVgV8YShTHGBMLevUTfUYe/NB/dM8wi7OW7mdMPMmXyOrArZ4nC\nGGOS0qZNnChQlmf7F+DQpSnsK1OfEROzU62a14FdPbvqyRhjksLRo9CpE5QrR+dSv/LJJ1Dm+fv5\ndW3qThJgLQpjjLl206cT/djj6MFDDOIFNmW7hcXToVYtrwNLGtaiMMaYa9GpEzz4IJuP5uMWXcHB\n3m+xYn1omkkSYC0KY4y5cqoAnDsvzIysyWpKMjV/H8aMz0Tdut6GFgiWKIwx5krs2gXdu7Oj5iM0\nnfIomzZ1o3t3WD0Ysmf3OrjAsERhjDH+iI6GESPQvn25cF4ZOOdhTtwIP/0EjRp5HVxg2TkKY4xJ\nzB9/QJ068MQTLOVWSl/cyMVHO7NxY9pPEmAtCmOMSVRUxB9cWBXOE0Hj+SHLo4z+QrjvPq+jSj6W\nKIwxJi5r1sDatWyq2ZH2A+9jy9kdNG55HeHDIHdur4NLXpYojDHG17lzMGAA+s47nMxegJpnWpMp\neyijv7qOFi28Ds4bdo7CGGNiLFkCVarAwIHMyv0oRY6tpd7doYSHk26TBFiLwhhjHHv3ovXqcTJH\nAdqGzGbR+YYMmQBt24KI18F5y1oUxpj0LSICgF2XCvBy2a+58cgGLtZrSHg4tGtnSQIsURhj0qu/\n/4YOHaB8eWb+3yIqVoSPdtzLB6OzMWsWFCjgdYAph3U9GWPSn6+/hp490SNH+Kp4PzoMrs6t9eCT\nT6BoUa+DS3ksURhj0pcOHeCzzzhStCr3h/7Eqn1VGPwx9OwJGayPJU6WKIwxaZ87iB8inKhwK9+V\nL0vH8GepcWtG1o2HkiU9jS7FC2j+FJHGIvKHiGwTkb5xLC8sIvNFZI2IrBeRJoGMxxiTDu3cCQ0b\nwoQJTJsGxQd1o+u253l7cEYWLbIk4Y+AJQoRCQKGAXcD5YDWIlIuVrGXgCmqejPQChgeqHiMMelM\nVBR8/DFUqIAuXcbIEcrDDzvnIFavhj59ICjI6yBTh0C2KKoD21R1h6peACYDzWKVUSCH+z4nsC+A\n8Rhj0otNm6B2bejdm4Nl63BLlnCeXNWB11+H336DcrF/spoEBfIcRQFgj890JFAjVpn+wBwReRLI\nCjSIa0Mi0g3oBlC4cOEkD9QYk8Zs20b05j8YW/tzuv/ahkqVhN/nODddmyvn9Tn+1sB4VS0INAE+\nF5H/xKSqo1U1TFXD8ubNm+xBGmNSgVWrnOtbgbmh91Ihy04eW9KWF18UVqywJHEtApko9gKFfKYL\nuvN8dQamAKjqUiAUyBPAmIwxac3Zs9C3L9SoQfSA1+nV7RwNG4Jmz8HSpfDmmxAS4nWQqVsgE8Xv\nQEkRKSYiwTgnq2fEKrMbqA8gImVxEsWhAMZkjElLFi2CypVh0CD2N+5AVdYwdGwozz7rnLCuXt3r\nANOGgCUKVb0EPAHMBjbhXN0ULiIDRCTmkR/PAl1FZB0wCeigGnPBszHGJGDvXqhfn+iLlxj+4M8U\nmDWWUxmvY9EiePddyJzZ6wDTDkltx+WwsDBduXKl12EYY7yyYQNUrAjA2jdm0nZcPcL/zErPnjBo\nEGTN6nF8KZSIrFLVsKtZ1+uT2cYY45/Dh53hXCtV4sTMRXTqBDe/3JQLmbKyYAEMHWpJIlBsCA9j\nTMqmClOnwhNPoEePEtH8VRp3qsH+v+GFF+Dll62bKdAsURhjUrb27eHzz7lQKYxny/3C0GkVqVYN\nZs51zmObwLNEYYxJeXwG8YuuXYdlpypxz9ynOB+Vkffeg169IKMdvZKNnaMwxqQsO3ZAgwYwfjyb\nN0OdCZ25bXofwmpmZONGeOYZSxLJzRKFMSZliIqCDz+EihXR339nxswMVK4M4eHw6acwZw7cdJPX\nQaZPlpeNMd6LiIBOnWD5co7ddg8PHxnJz98UpGVL+OgjuOEGrwNM36xFYYzx3s6d6LbtTGj8Jdcv\n+Z5NJwvy3XcwebIliZTAEoUxxhu//w5jxgAwO+M9VMy6g/Y/teaxx4WICLjvvkTWN8nGEoUxJnmd\nOeM8NahmTaLeHEjnNudo3BiismTn119h2DDIkSPxzZjkY4nCGJN8FiyASpXgvffYWq8rpU6tYcKU\nUF5+Gdasgdtv9zpAExdLFMaY5BEZCXfdxcVL8EKNeZT6ZSR5iudk9WoYMABCQ70O0MTHEoUxJrDW\nrQMgKn9Bvu/yHQUOr+fjDfX48EPnsaTu+H4mBbNEYYwJjEOH4JFHoEoV/vxsIbVrw30jm1D19iyE\nh0Pv3hAU5HWQxh92H4UxJmmpOte19uqFHj/Ogrqv0bRLLTLnhM8/hzZtQMTrIM2V8KtFISLBIlIi\n0MEYY9KAdu3gkUc4eUNxmhVaw50LXuH+FsFs2gRt21qSSI0STRQicg+wAZjrTlcRkemBDswYk4pE\nR/8zkN+5WvX45vb3yRW+hLUXy/PDD/DFF5A3r8cxmqvmT4tiAFADOAagqmsBa10YYxzbtkH9+vDp\np8yaBaUGdab5kqd5/MkgwsOhSROvAzTXyp9EcVFVj8Wal7qen2qMSXqXLjkPp65YkejVaxg2Jph7\n7oHs2WHJEvj4Y+e9Sf38OZm9SURaABlEpBjQC1gW2LCMMSnaxo3QsSOsXMmeqs24e+dwtqy6kf79\noW9fCAnxOkCTlPxpUTwBVAOigW+A80DvQAZljEnhdu8maucu3qo0mcKrp5OjzI2sXQuvvmpJIi3y\np0XRSFWfB56PmSEiD+IkDWNMerF8OaxbR1TnbgzZ0oS3zuzg7I5sDBkCjz8OGeyurDTLn//al+KY\n1y+pAzHGpFCnTzuPlatVi/NvvEOdmud5+mm4pV42wsPhiScsSaR18bYoRKQR0BgoICLv+yzKgdMN\nZYxJ6+bNg65dYccOlld7jLvXvk3Q2RC+/BJatbJ7ItKLhLqeDgIbgXNAuM/8k0DfQAZljEkBIiOh\nUSPO5itGt8ILmbjqDh59FN57D/Lk8To4k5ziTRSqugZYIyJfqOq5ZIzJGOOlNWvg5ps5kaMgnzf+\nnj4z63BDkcz89BM0auR1cMYL/vQsFhCRySKyXkS2xLwCHpkxJnkdOAAtW0LVqvw2cCHlysGTPzSm\nx1OZ2bjRkkR65k+iGA98CghwNzAF+CqAMRljkpMqTJwI5cqh337L5ApvUOfFW8mVC5YuhQ8+gGzZ\nvA7SeMmfRJFFVWcDqOp2VX0JJ2EYY9KCRx6Bdu04mKs0tULX0n5LP/q/kYlVq6BGDa+DMymBP/dR\nnBeRDMB2EekB7AXsxnxjUrPoaOeSJREO3tyQKatr0XtLT269PYh1Y6BMGa8DNCmJP4niaSArztAd\nbwI5gU6BDMoYE0BbtkDXrkS1eZQPT3bm5f4dyZgRho2Abt3sngjzX4kmClVd7r49CbQDEJECgQzK\nGBMAly7B++/Dq69yKVMo/fdk5s2dcN99MGwYFCzodYAmpUowUYjILUABYLGqHhaR8jhDedwJ2NfK\nmNRi/Xro1AlWrSK81AM02jaMi5nzM2UKNG9uN86ZhMXbyBSRgcAXQBvgJxHpD8wH1gGlkiU6Y0zS\niIzkwo49PJlvKhW2fE3D9vnZtAkeftiShElcQi2KZkBlVT0rItcDe4CKqrrD342LSGPgIyAIGKuq\nb8dRpgXQH+cZF+tU9ZEriN8YE5/ffoP16znWqgfPf9eEiUd3kO+mrMydCw0aeB2cSU0SShTnVPUs\ngKr+LSJbrjBJBAHDgLuASOB3EZmhqhE+ZUoCLwC3qepREfnfVX0KY8xlp05Bv34wZAin8hWnymsd\n2XMwhGf6ZOW11yBLFq8DNKlNQoniJhGJGUpcgGI+06jqg4lsuzqwLSa5iMhknFZKhE+ZrsAwVT3q\nbvPgFcZvjPE1Zw5064bu3s2PN/Wk5fa3KF45hK9nQrVqXgdnUquEEsVDsaaHXuG2C+B0V8WIxHn2\ntq9SACKyBKd7qr+q/hR7QyLSDegGULhw4SsMw5h0Ys8e9J57OJ6nOK2zLmJ+5O30HwjPPguZMnkd\nnEnNEhoU8Jdk2n9JoC7OVVSLRKRi7Gd0q+poYDRAWFiYPa/bGF+rVkG1amw7X4hR5WcxZF1tatYJ\nZf1oKGWXnZgkEMhba/YChXymC7rzfEUCM1T1oqruBLbgJA5jTGL++su5bCksjC+7L6RiRRjz510M\nGR3KvHmWJEzSCWSi+B0oKSLFRCQYaAXMiFXmW5zWBCKSB6cryu8T5sakS6rw2WdQrhzRM75nSP63\naD/6Vu6+GyIinOcM2d3VJin5M4QHACISoqrn/S2vqpdE5AlgNs75h09UNVxEBgArVXWGu6yhiEQA\nUcBzqnrkyj6CMelMq1YwZQo7C9xG0+Nj+VvL8NXX8GBil5cYc5USTRQiUh0YhzPGU2ERqQx0UdUn\nE1tXVWcBs2LNe8XnvQLPuC9jTHx8BvGLKNqEqXlq89rex+nSNQPvvAPXXed1gCYt86dF8THQFKeb\nCFVdJyL1AhqVMeayzZuhSxdOP9yBXuu78Mkn7SlRAn6ZAvXsL9EkA38SRQZV3SX/vs8/KkDxGGNi\nXLwIgwejr73GxUxZeWZjNj47Bc8/D6++Cpkzex2gSS/8SRR73O4nde+2fhLn6iRjTKCsXQsdO8La\ntfx2Y3Me2jeEAlXz8ftYuPlmr4Mz6Y0/10Y8hnMOoTBwAKjpzjPGBEj0vr84veMv2mb+mruOTqXP\n4HwsX25JwnjDnxbFJVVtFfBIjEnvFi+G9ev5o/7jdBvUmN9PbKfWnVnYMBqKF/c6OJOe+dOi+F1E\nZolIexGxR6Aak9ROnoQnnoDatTnyyofcUuk869fD0HFZ+PlnSxLGe4kmClUtDrwBVAM2iMi3ImIt\nDGOSwuzZUKECOnw4E/P0psiR1TRuFsKmTc5zhuxZESYl8Ov+TVX9TVV7AVWBEzgPNDLGXIs9e9Cm\nTTlwKgu1WczzwR/yxbfZmDIF8uXzOjhjLks0UYhINhFpIyLfAyuAQ8CtAY/MmLRIFVasAGDOpkK0\ny/0jRf5eQ8XutxIRAc2aeRyfMXHw52T2RuB74B1V/TXA8RiTdu3fDz17wvTpDGy0gBdn16FUqQbM\nnQq1a3sdnDHx8ydR3KSq0QGPxJi0ShXGj0efeYao0+d4K+sg3vr5Nvr1g5degtBQrwM0JmHxJgoR\neU9VnwW+FpH/PAPCjyfcGWMAWrSAadMIv742D14cS87KpVg+FipX9jowY/yTUIviK/ffK32ynTEm\nKgpEiCYD87Pcy8yQOxlztjuvv5+BXr0gKMjrAI3xX0JPuFvhvi2rqv9KFu7w4cnxBDxjUp9Nm6Bz\nZ/Y37kjz2V357bdHuesu2DAKihXzOjhjrpw/l8d2imNe56QOxJhU7+JFeOMNtEoVzqz9g2cH5GTz\nZucZQ7NnW5IwqVdC5yha4jyVrpiIfOOzKDtwLO61jEmn1qyBDh1g/Xp+ytGS9ic+pkHr/7HpQ/jf\n/7wOzphrk9A5ihXAEZxnXQ/zmX8SWBPIoIxJbc7+eYDz2w/TgW9ZlaMZn3wBTZt6HZUxSSOhcxQ7\ngZ3Az8kXjjGpyKJFsGEDPxXvSfenGnPo9DY69czMhLcgRw6vgzMm6STU9bRQVeuIyFHA9/JYwXmK\n6fUBj86YlOjECejbF0aMYH/2UjQ72YXiZUP4cnFmbrvN6+CMSXoJncyOechiHiCvzytm2pj0Z9Ys\ntHx5okeOYnjoM5Q9u5q+r4SwZg2WJEyalVDXU8zd2IWAfap6QURuByoBE3EGBzQm/dizB23WjF2h\npWmp05DKNVg8FipU8DowYwLLn8tjv8V5DGpx4FOgJPBlQKMyJqVQhWXLiIqCj6cX4p6Mc7g5ejVt\nPqrBkiWWJEz64E+iiFbVi8CDwBBVfRooENiwjEkB9u2D+++HWrV4stJCevcGrVuPtRHBdne1SVf8\nSRSXRORhoB0w052XKXAhGeMxVRg7Fi1Xjouz5vB/Gd7l679uY+JEmDULihTxOkBjkpe/d2bXwxlm\nfIeIFAMmBTYsYzzUvDl07crvF6tQ9tIG9j/yLBs3Z6RNG3vinEmfEh1mXFU3ikgvoISIlAG2qeqb\ngQ/NmGTkDuJ38nQGvjlxP0tpyE+5uzLy6ww0bux1cMZ4y58n3NUGtgHjgE+ALSJiFwKatGPjRrjt\nNtb3Hke5ctDxl3aE9u7OxghLEsaAfw8u+gBooqoRACJSFvgcCAtkYMYE3IULMHAg+uabnMyQkwHL\nc5GzPEydCjVreh2cMSmHP+cogmOSBICqbgKCAxeSMclg1Sq0WjXo359p8jBloyOoPKA5q1dbkjAm\nNn9aFKtFZCTOTXYAbbBBAU0q91f4EYK2HqMj33M0rClzx0C5cl5HZUzK5E+i6AH0Av7Pnf4VGBKw\niIwJlPnziV63gQ+je/Hyyw3JnHErA94PpUcPyOBP29qYdCrBRCEiFYHiwHRVfSd5QjImiR0/Dv/3\nfzB6NLtCy/DCue40bBrC8OGhFCrkdXDGpHzx/o4SkRdxhu9oA8wVkbiedGdMyvb992jZckSPGct7\n0oe62VYxYXIIM2ZgScIYPyXUomgDVFLV0yKSF5iFc3msManDnj1EP/gQWzOUoa1+S/n2t7D6Pcid\n2+vAjEldEkoU51X1NICqHhIR68U1KZ8qLF3K8fK30vetQmy6NId9RW5l2Jhg7rrL6+CMSZ0SOvjf\nJCLfuK/pQHGf6W8SWO8fItJYRP4QkW0i0jeBcg+JiIqI3Zthrl5kJNx3H9x2G52KL2T0aKj2TF3W\nhFuSMOZaJNSieCjW9NAr2bDdAgkxAAAZuElEQVSIBOE8a/suIBL4XURm+N6T4ZbLDvQGll/J9o35\nR3Q0jBlDdJ/nuHj2En15nx033s6yH+GWW7wOzpjUL6EHF/1yjduujjMu1A4AEZkMNAMiYpV7HRgE\nPHeN+zPplD70EPLtt/ya8U56BI2h3YCbWPEcZLIxjo1JEv7cR3G1CgB7fKYjgRq+BUSkKlBIVX8Q\nkXgThYh0A7oBFC5cOAChmlTn0iXIkIHtOzMwZctDbOcettTszLdjhdKlvQ7OmLTFsxPU7snx94Fn\nEyurqqNVNUxVw/Lmtcd1p3vr16M1azHn4TFUrAhvR7bllpFdWLDQkoQxgeB3ohCRkCvc9l6c523H\nKOjOi5EdqAAsEJE/gZrADDuhbeJ1/jy8+iparRpH1+1i5Dd5adgQIiKge3e7u9qYQPFnmPHqIrIB\n2OpOVxYRf4bw+B0oKSLFRCQYaAXMiFmoqsdVNY+qFlXVosAy4D5VXXk1H8Skcb//TvTNVWHAACZG\ntea2XJt4ZOqDTJ8OBezBvMYElD/nKD4GmuLcpY2qrhOReomtpKqXROQJYDYQBHyiquEiMgBYqaoz\nEt6CMZetW3CUPFtP0YVZFOh0N78Nhly5vI7KmPTBn0SRQVV3yb+fARnlz8ZVdRbOHd2+816Jp2xd\nf7Zp0pF58zizYgO9t/dm7NiGlCm2hWFjQ7jzTq8DMyZ98SdR7BGR6oC690Y8CWwJbFgmXTt2DJ57\nDsaOJTKoLBOje/DccyH07x9ClixeB2dM+uNPongMp/upMHAA+NmdZ0zS++47oro/BgcO8C7/x/Ty\n/VnyaQhVq3odmDHpV6KJQlUP4pyINiagov/cjT70MJu0LN2DZ9Ds9TB+fdpunDPGa4kmChEZA2js\n+araLSARmfRFFRYvZmu+2nTtWpjoqJ8JuaMm48cGU7Kk18EZY8C/rqeffd6HAg/w7zuujbk6u3cT\n3b0HGX76kcczLWBtljq8O+YOOneGf187YYzxkj9dT1/5TovI58DigEVk0r7oaBg5kqjnnuf8OeV5\nPibXvbezaSjkz+91cMaY2K7mXtZiwA1JHYhJPy41exB69mTemVrUzb2RO795kilfB1mSMCaF8ucc\nxVEun6PIAPwNxPtsCWPi5A7i9/O8DMxc0ZLjNCO4awfmvCNcd53XwRljEpJgohDnLrvKXB6jKVpV\n/3Ni25gErVvHpfad+DJLV9ov7UHJkq0ZMwXq1PE6MGOMPxLsenKTwixVjXJfliSM/86dQ/u9RHS1\nMI6uj+Tb5fl44QVYt86ShDGpiT9XPa0VkZtVdU3AozFpx4oVXGzTnkzbNvMZ7ZlQ+X0++Ox6Klf2\nOjBjzJWKN1GISEZVvQTcjPMY0+3AaUBwGht2r6yJU3Q0zPziBJW3n+XJ4J+o81Yj5vSGjIF8TJYx\nJmAS+tNdAVQF7kumWExqN2cOB+aF03zJ0yxe3IC77/yDoWNCuOkmrwMzxlyLhBKFAKjq9mSKxaRW\nR48S9dQzBE0Yz2Epz9acj/PppyG0bx9iN84ZkwYklCjyisgz8S1U1fcDEI9Jbb75hgvdepLhyCHe\n4gU2PfQK64aGcIPdaWNMmpFQoggCsuG2LIyJ7czm3QQ/3IqN0RV4Ie8seo69mReto9KYNCehRLFf\nVQckWyQmdVCFRYuYfa4OPXoUpkD0PKp0q8GUdzKRM6fXwRljAiHRcxTG/GPXLi506k7wvNm8xQJC\nStfh7V9v5/bbvQ7MGBNICd1wVz/ZojApW3Q0OmQoF0uX5+K8xfTOMIQ6/Wqzdi2WJIxJB+JtUajq\n38kZiEm5zjS6nyw/f88vNGJE5VG88XkRKlb0OipjTHKxW6BM3C5eJFqCGD4yA6t+bU3G4OZUGNSO\nb54UgoK8Ds4Yk5wsUZj/Wr2as206M+x8V57b+TgNG7Zm1CgoWtTrwIwxXria51GYtOrsWS499wLR\nYdU5tvkvVh8qxIQJ8NNPliSMSc+sRWEcy5ZxtmV7Mu/ewjg6saz5u3w4LBf/+5/XgRljvGYtCsPJ\nkzB00Gn2777II3nnkv+HcYyZaknCGOOwFkV69tNPbJoWTqM5zxIZWZ/tj29m1NvBZM/udWDGmJTE\nEkV6dOQI5x5/htApE7hIRXKVeZKvlgRTq1aw15EZY1IgSxTpiSo67WvOdelJxhN/81aGl4h+8SVW\nvBRMSIjXwRljUipLFOnIniW7ydfyEcK1Eh9VnEPfSZUpX97rqIwxKZ2dzE7rVImaO48PP4QyjYpw\nd+gCln+4jPFrLEkYY/xjLYq0bOdOTj7SjezLfmY6C6jbpA4jRtxK4cJeB2aMSU2sRZEWRUVx6b2P\nuFC6ArpsOX2yjqDHxNrMnIklCWPMFbMWRRr0d+1mXL/0B36gCXMfHMlLowqRJ4/XURljUitLFGnF\nxYucOB3EC/0ycHhpO/Llbk2TiY/wYWN7rIgx5toEtOtJRBqLyB8isk1E+sax/BkRiRCR9SLyi4gU\nCWQ8adbKlRwvFcagoiMYMQJufKolb/7ZhkaWJIwxSSBgiUJEgoBhwN1AOaC1iJSLVWwNEKaqlYBp\nwDuBiidNOnuW0088T3T1Gpz+8xDHchZh6VL44APIls3r4IwxaUUgu56qA9tUdQeAiEwGmgERMQVU\ndb5P+WVA2wDGk6bob0s58WB7ch7YyrgMXTj64mA+eOU6gu3mamNMEgtkoigA7PGZjgRqJFC+M/Bj\nXAtEpBvQDaCwXbbDjh0w4smzdD8QzasVfqbH1PqUKeN1VMaYtCpFnMwWkbZAGFAnruWqOhoYDRAW\nFqbJGFqKEvX9LBaPCufuec+RMeOdlBiyifcfz0QGu8jZGBNAgTzE7AUK+UwXdOf9i4g0APoB96nq\n+QDGk3odPszRe9oSdN895PzhCxrfeYGICOj+hCUJY0zgBfIw8ztQUkSKiUgw0AqY4VtARG4GRuEk\niYMBjCV1UuXChMmcLlyWrLOmMDjLq2z7YgVffx9MwYJeB2eMSS8C1vWkqpdE5AlgNhAEfKKq4SIy\nAFipqjOAwUA2YKqIAOxW1fsCFVNqs2zKbqp2aE+4Vub7ZuN4+pOKXH+911EZY9IbUU1dXf5hYWG6\ncuVKr8MIHFVOffcLz/7YgNGj4YH8y3j801to0CjI68iMMamYiKxS1bCrWdd6uFOS7ds5VKk+2R64\niy1jFtKnD3y+taYlCWOMp1LEVU/pXlQUJ17/iJA3XiI4KhOvFxzF4K9rE1bd68CMMcYShedUIbLK\nvRTa+CM/ZGjKn31H0HdAQTJl8joyY4xxWKLwyoULbPszI916ZCDPxg5UKNuOVtNbcU9pG5/JGJOy\n2DkKD1z6bQWHCldjWPnhrF4Nd41uwUsbW1PKkoQxJgWyRJGczpzhQNtnkdtqcf7AUa6/pTgREdC1\nK3bjnDEmxbKup2Ry7ufFnH64PTcc28GEzN25btQgXm6X0+uwjDEmUZYoksG8efBJ+4u8ciyIT5rM\np8vEuuTK5XVUxhjjH+vwCKBTk75n6i3vUL8+LM9Sj31zI3juB0sSxpjUxRJFAOjBQ+y+/RGyPXIf\nJVZO4sU+F1i/Huo2sAacMSb1sUSRlFT5e+iXnCxUlnxLpjEi/wBk+XLeHBxM5sxeB2eMMVfHEkUS\niY6GLwbuJuuTHdl8sQQTn1lD190vU6W6PXLOGJO6WV/ItYqOZs8nc2n7eSMWLSrCkrBfeWZiNTqV\ntvGZjDFpgyWKa3AxYiv7mnalyM6FZMu2kHHj7qBjx+qI3TdnjElDLFFcjUuX2PPMB+Qd+go5NYQR\nYeMYN6M2+fJ7HZgxxiQ9SxRX6PRp2FO+KWV2zean0GbI8OE81vFGr8MyJkW6ePEikZGRnDt3zutQ\n0o3Q0FAKFixIpiQcWdQShb/On2fugkx0fywDVXd1oVGDTrSY+jA5r7N+JmPiExkZSfbs2SlatChi\nfbIBp6ocOXKEyMhIihUrlmTbtaue/HB89jL23lCVGY2HkSkT9FrYnK5zW1iSMCYR586dI3fu3JYk\nkomIkDt37iRvwVmiSICeOs0fTZ4me+NbiTp+krBWJVm3Du64w+vIjEk9LEkkr0DUt3U9xePAtF/R\n9u0pfWYnU/M+TpnpA2l/Ww6vwzLGmGRnLYpYoqNh+HDo9OglTpzNxJSeC3lw/zAqWpIwJtX69ttv\nERE2b978z7wFCxbQtGnTf5Xr0KED06ZNA5wT8X379qVkyZJUrVqVWrVq8eOPP15zLAMHDqREiRKU\nLl2a2bNnx1mmQ4cOFCtWjCpVqlClShXWrl0LOOcgevXqRYkSJahUqRKrV6++5nj8YS0KH3uGfMsP\n726i5+4XuOuuemQaFk6LklZFxqR2kyZN4vbbb2fSpEm89tprfq3z8ssvs3//fjZu3EhISAgHDhxg\n4cKF1xRHREQEkydPJjw8nH379tGgQQO2bNlCUNB/b9AdPHgwzZs3/9e8H3/8ka1bt7J161aWL1/O\nY489xvLly68pJn/YURC4sOcA2+5+knLhU6kZVJUJY5+lbadgRKx6jEkqTz0F7g/jJFOlCnz4YcJl\nTp06xeLFi5k/fz733nuvX4nizJkzjBkzhp07dxISEgLADTfcQIsWLa4p3u+++45WrVoREhJCsWLF\nKFGiBCtWrKBWrVp+r//oo48iItSsWZNjx46xf/9+8ucP7E1c6bvrSZVtr37OmWLlKB7+HZMrvkn+\nP5fRrnOw3V1tTBrx3Xff0bhxY0qVKkXu3LlZtWpVouts27aNwoULkyNH4l3OTz/99D9dRL6vt99+\n+z9l9+7dS6FChf6ZLliwIHv37o1zu/369aNSpUo8/fTTnD9//orXT0rp9ifzqVPwXq/d9P20C+uD\nwzg1ZBytHivjdVjGpFmJ/fIPlEmTJtG7d28AWrVqxaRJk6hWrVq8Vwdd6VVDH3zwwTXHGNvAgQPJ\nly8fFy5coFu3bgwaNIhXXnklyffjr/SXKKKjWfnmbB4aezd79hQh88NL6DHqZnLkskH8jElr/v77\nb+bNm8eGDRsQEaKiohARBg8eTO7cuTl69Oh/yufJk4cSJUqwe/duTpw4kWir4umnn2b+/Pn/md+q\nVSv69u37r3kFChRgz549/0xHRkZSoECB/6wb05UUEhJCx44deffdd69o/SSnqqnqVa1aNb1aR5b9\noZvy1lYFbVd4gS5efNWbMsb4ISIiwtP9jxo1Srt16/aveXfccYcuXLhQz507p0WLFv0nxj///FML\nFy6sx44dU1XV5557Tjt06KDnz59XVdWDBw/qlClTrimejRs3aqVKlfTcuXO6Y8cOLVasmF66dOk/\n5fbt26eqqtHR0dq7d299/vnnVVV15syZ2rhxY42OjtalS5fqLbfcEud+4qp3YKVe5XE3XZyj0IuX\nWNN6EFlqVuKGQxuYft+njPnjDm67zevIjDGBNGnSJB544IF/zXvooYeYNGkSISEhTJw4kY4dO1Kl\nShWaN2/O2LFjyZkzJwBvvPEGefPmpVy5clSoUIGmTZv6dc4iIeXLl6dFixaUK1eOxo0bM2zYsH+u\neGrSpAn79u0DoE2bNlSsWJGKFSty+PBhXnrppX/K3HTTTZQoUYKuXbsyfPjwa4rHX+IkmtQjLCxM\nV65c6Xf5XbvgcFgjqh2ew/xcD5L/m2GUqZsvgBEaY2Js2rSJsmXLeh1GuhNXvYvIKlUNu5rtpdkW\nRdTpcwz5MIry5eH9k934oeM07jj0tSUJY4y5QmnyZPaOz5cQ1K0zW889Tu3GvXhr5EMUKeJ1VMYY\nkzqlqRbF+SOnWFajF0UfrY1cOEez58syaxaWJIzxUGrr3k7tAlHfaSZRbBy2kMP5K1B9xVDmln6C\nzNs2Uv/tu+zGOWM8FBoaypEjRyxZJBN1n0cRGhqapNtN9V1PJ0/CCy/AxmEwJmMWlg/+lUZ97HIm\nY1KCggULEhkZyaFDh7wOJd2IecJdUkrViWJVv2/4eehmhp98kSd71SH/gA2UzGk3zhmTUmTKlClJ\nn7RmvBHQricRaSwif4jINhHpG8fyEBH5yl2+XESK+rPdwxv/Ynmh5lR76yHuuTCdpQsv8NFHkM2S\nhDHGJLmAJQoRCQKGAXcD5YDWIlIuVrHOwFFVLQF8AAxKbLundh0hY6WyVI6cyS8NBlLq8G/UqB2c\n1OEbY4xxBbJFUR3Ypqo7VPUCMBloFqtMM+Az9/00oL4kMiJX1sO72JWtApEz11F/bl+Cs2ZK8sCN\nMcZcFshzFAWAPT7TkUCN+Mqo6iUROQ7kBg77FhKRbkA3d/J8lZOLN9LURnoF8hCrrtIxq4vLrC4u\ns7q4rPTVrpgqTmar6mhgNICIrLza29DTGquLy6wuLrO6uMzq4jIR8X/so1gC2fW0FyjkM13QnRdn\nGXEeJ5cTOBLAmIwxxlyhQCaK34GSIlJMRIKBVsCMWGVmAO3d982BeWp35hhjTIoSsK4n95zDE8Bs\nIAj4RFXDRWQAzrjoM4BxwOcisg34GyeZJGZ0oGJOhawuLrO6uMzq4jKri8uuui5S3TDjxhhjklea\nGevJGGNMYFiiMMYYk6AUmygCNfxHauRHXTwjIhEisl5EfhGRNDuwemJ14VPuIRFREUmzl0b6Uxci\n0sL9boSLyJfJHWNy8eNvpLCIzBeRNe7fSRMv4gw0EflERA6KyMZ4louIfOzW03oRqerXhq/2YduB\nfOGc/N4O3AQEA+uAcrHKPA6MdN+3Ar7yOm4P66IekMV9/1h6rgu3XHZgEbAMCPM6bg+/FyWBNUAu\nd/p/XsftYV2MBh5z35cD/vQ67gDVxR1AVWBjPMubAD8CAtQElvuz3ZTaogjI8B+pVKJ1oarzVfWM\nO7kM556VtMif7wXA6zjjhp1LzuCSmT910RUYpqpHAVT1YDLHmFz8qQsFcrjvcwL7kjG+ZKOqi3Cu\nII1PM2CCOpYB14lI/sS2m1ITRVzDfxSIr4yqXgJihv9Ia/ypC1+dcX4xpEWJ1oXblC6kqj8kZ2Ae\n8Od7UQooJSJLRGSZiDROtuiSlz910R9oKyKRwCzgyeQJLcW50uMJkEqG8DD+EZG2QBhQx+tYvCAi\nGYD3gQ4eh5JSZMTpfqqL08pcJCIVVfWYp1F5ozUwXlXfE5FaOPdvVVDVaK8DSw1SaovChv+4zJ+6\nQEQaAP2A+1T1fDLFltwSq4vsQAVggYj8idMHOyONntD253sRCcxQ1YuquhPYgpM40hp/6qIzMAVA\nVZcCoTgDBqY3fh1PYkupicKG/7gs0boQkZuBUThJIq32Q0MidaGqx1U1j6oWVdWiOOdr7lPVqx4M\nLQXz52/kW5zWBCKSB6crakdyBplM/KmL3UB9ABEpi5Mo0uPzWWcAj7pXP9UEjqvq/sRWSpFdTxq4\n4T9SHT/rYjCQDZjqns/frar3eRZ0gPhZF+mCn3UxG2goIhFAFPCcqqa5VrefdfEsMEZEnsY5sd0h\nLf6wFJFJOD8O8rjnY14FMgGo6kic8zNNgG3AGaCjX9tNg3VljDEmCaXUridjjDEphCUKY4wxCbJE\nYYwxJkGWKIwxxiTIEoUxxpgEWaIwKY6IRInIWp9X0QTKFo1vpMwr3OcCd/TRde6QF6WvYhs9RORR\n930HEbnRZ9lYESmXxHH+LiJV/FjnKRHJcq37NumXJQqTEp1V1So+rz+Tab9tVLUyzmCTg690ZVUd\nqaoT3MkOwI0+y7qoakSSRHk5zuH4F+dTgCUKc9UsUZhUwW05/Coiq93XrXGUKS8iK9xWyHoRKenO\nb+szf5SIBCWyu0VACXfd+u4zDDa4Y/2HuPPflsvPAHnXnddfRPqISHOcMbe+cPeZ2W0JhLmtjn8O\n7m7LY+hVxrkUnwHdRGSEiKwU59kTr7nzeuEkrPkiMt+d11BElrr1OFVEsiWyH5POWaIwKVFmn26n\n6e68g8BdqloVaAl8HMd6PYCPVLUKzoE60h2uoSVwmzs/CmiTyP7vBTaISCgwHmipqhVxRjJ4TERy\nAw8A5VW1EvCG78qqOg1YifPLv4qqnvVZ/LW7boyWwOSrjLMxzjAdMfqpahhQCagjIpVU9WOcIbXr\nqWo9dyiPl4AGbl2uBJ5JZD8mnUuRQ3iYdO+se7D0lQkY6vbJR+GMWxTbUqCfiBQEvlHVrSJSH6gG\n/O4Ob5IZJ+nE5QsROQv8iTMMdWlgp6pucZd/BvQEhuI862KciMwEZvr7wVT1kIjscMfZ2QqUAZa4\n272SOINxhm3xracWItIN5+86P84DetbHWremO3+Ju59gnHozJl6WKExq8TRwAKiM0xL+z0OJVPVL\nEVkO3APMEpHuOE/y+kxVX/BjH218BxAUkevjKuSOLVQdZ5C55sATwJ1X8FkmAy2AzcB0VVVxjtp+\nxwmswjk/MQR4UESKAX2AW1T1qIiMxxn4LjYB5qpq6yuI16Rz1vVkUoucwH73+QHtcAZ/+xcRuQnY\n4Xa3fIfTBfML0FxE/ueWuV78f6b4H0BRESnhTrcDFrp9+jlVdRZOAqscx7oncYY9j8t0nCeNtcZJ\nGlxpnO6Adi8DNUWkDM7T204Dx0XkBuDueGJZBtwW85lEJKuIxNU6M+YflihMajEcaC8i63C6a07H\nUaYFsFFE1uI8l2KCe6XRS8AcEVkPzMXplkmUqp7DGV1zqohsAKKBkTgH3Znu9hYTdx//eGBkzMns\nWNs9CmwCiqjqCnfeFcfpnvt4D2dU2HU4z8feDHyJ050VYzTwk4jMV9VDOFdkTXL3sxSnPo2Jl40e\na4wxJkHWojDGGJMgSxTGGGMSZInCGGNMgixRGGOMSZAlCmOMMQmyRGGMMSZBliiMMcYk6P8BB/mC\ngE+D2awAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4bTOl8i8PoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tch1Y9lF8Pk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT4Hfs108Phk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2sBkx3qY9RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrAjWMMPY9bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj58xsZKY9NW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7RaQAfRY9Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0l80VVFY9GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}